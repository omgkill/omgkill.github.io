[{"categories":null,"contents":" 忽略 使用docker部署gollum, dockerFile\n1FROM ruby:2.4.1-alpine 2MAINTAINER ilanni \u0026lt;ilanni@ilanni.com\u0026gt; 3RUN set -xe \\ 4\u0026amp;\u0026amp; echo \u0026#34;https://mirrors.aliyun.com/alpine/v3.4/main\u0026#34; \u0026gt; /etc/apk/repositories \\ 5\u0026amp;\u0026amp; echo \u0026#34;https://mirrors.aliyun.com/alpine/v3.4/community\u0026#34; \u0026gt;\u0026gt; /etc/apk/repositories \\ 6\u0026amp;\u0026amp; apk --update add alpine-sdk icu-dev git rsync openssh \\ 7\u0026amp;\u0026amp; gem install gollum github-markdown \\ 8\u0026amp;\u0026amp; rm -rf /var/cache/apk/* \\ 9\u0026amp;\u0026amp; mkdir -p /gollum/ \\ 10\u0026amp;\u0026amp; git init /gollum/ 11# Expose default gollum port 4567 12EXPOSE 4567 13 14ENTRYPOINT [\u0026#34;/usr/local/bundle/bin/gollum\u0026#34;, \u0026#34;/gollum/\u0026#34;] 另一个dockerfile 1 FROM ruby:2.4.1-alpine 2 RUN apt-get -y update \u0026amp;\u0026amp; apt-get -y install libicu-dev 3 RUN gem install gollum 4 RUN gem install github-markdown org-ruby 5 # RUN gem install --pre gollum-rugged_adapter 6 RUN apt-get -y install cmake 7 RUN gem install gollum-rugged_adapter 8 VOLUME /wiki 9 WORKDIR /wiki 10 CMD [\u0026#34;gollum\u0026#34;, \u0026#34;--port\u0026#34;, \u0026#34;80\u0026#34;, \u0026#34;--adapter\u0026#34;, \u0026#34;rugged\u0026#34;, \u0026#34;--emoji\u0026#34;, \u0026#34;--no-edit\u0026#34;,\u0026#34;--css\u0026#34;,\u0026#34;--js\u0026#34;] 11 12 EXPOSE 80 运行docker命令\n1 docker run --rm --privileged=true --name gollum -d -v D:/gg/wiki:/wiki -p 4567:4567 gollumwiki/gollum:master --css --js 启动后会报错 git repository 没有权限，或者不是当前用户等 ，进入docker里\ncd /wiki 设置这个 git config \u0026ndash;global \u0026ndash;add safe.directory /wiki 参考文档：\nhttps://www.ilanni.com/?p=13702 ","permalink":"https://omgkill.github.io/post/wiki/%E6%90%AD%E5%BB%BAgollum/","tags":null,"title":"搭建gollum"},{"categories":["blob"],"contents":"博客搭建 整体的说明（使用 Hugo 搭建博客）：https://www.diguage.com/post/building-blog-with-hugo/\n搭建具体流程：\nhttps://blog.csdn.net/weixin_52473454/article/details/131092259\n安装hugo的时候，安装完，还需要安装extend版本。从hugo github找到extend版本，然后找到hugo.exe，然后用下载的替换 添加搜索：\nhttps://sobaigu.com/hugo-set-featuer-search.html\n搜索参考：\nhttps://fasionchan.com/\n我们可以用搜索引擎来搜索呀。这样搜索效果更好 关于博客文档的说明：https://github.com/xianmin/hugo-theme-jane/blob/master/README-zh.md\n博客主题参考\nhttps://hugoloveit.com/zh-cn/posts/ hugo中文文档：https://hugocn.netlify.app/about.html\n发布 ： hugo \u0026ndash;theme=jane \u0026ndash;baseURL=\u0026ldquo;https://omgkill.github.io/\u0026quot; \u0026ndash;buildDrafts\n生成文件 ：hugo \u0026ndash;theme=jane \u0026ndash;baseURL=\u0026ldquo;https://omgkill.github.io/\u0026quot;\n(但我没成功执行这个命令，我是克隆的)对与项目中包含submodule， clone下来应该没有submoudle的data。可以执行git submodule update \u0026ndash;init \u0026ndash;recursive\n","permalink":"https://omgkill.github.io/post/blob/blob_deploy/","tags":["blob"],"title":"博客搭建"},{"categories":["git"],"contents":"git 使用 远程仓库的使用 查看远程仓库\ngit remote 看到origin 这是git给你克隆的仓库服务器的 默认名字 git remote -v 会显示名字与url，拉取与推送会独立显示 添加远程仓库\ngit remote add 从远程仓库拉取\ngit fetch [remote-name] fetch 命令会将数据拉去到你的本地仓库，它并不会自动合并或修改你当前的工作。当准备好时你必须手动将其合并入你的工作 git clone\n命令会自动将其添加为远程仓库 并默认以‘origin’ 为简写 git fetch origin 会抓取克隆（或上次抓取）后新推送的所有工作 会自动设置本地master分支跟踪克隆的远程仓库的master分支 git pull\n自动抓取然后合并远程分支到当前分支 fetch 与pull区别\ngit fetch：从远程获取最新版本到本地，但不会自动 merge，用于从远程跟踪分支下载和查看其他人完成的最新提交，但不将这些提交合并到本地存储库中。它从远程存储库中获取更改并将其存储在本地存储库中。\ngit pull：从远程获取最新版本并 merge 到本地，它会自动将提交合并到您的本地存储库中，而无需查看提交。\n参考：https://worktile.com/kb/ask/22877.html\n查看分支\ngit branch -a *rebase和merge区别*\n参考：https://baijiahao.baidu.com/s?id=1726894961804450124\u0026amp;wfr=spider\u0026amp;for=pc\ngit IDEA的分支合并时的冲突问题总结，merge和rebase的区别_rebase和merge的区别_YHJ的博客-CSDN博客\n撤回\n在当前分支，打开终端，执行命令回退 git reset --hard commit_id。 推送到远程仓库\ngit push origin master 如果远程仓库与本地有冲突，可以先把master拉取下来合并，解决完冲突，再推送 查看远程仓库\ngit remote show [remote-name] 实例：git remote show origin 本地远程仓库的重命名\ngit remote rename [原名字] [新名字] git remote rename pb paul git remote 查看本地简称是否修改 本地远程仓库的删除\ngit remote rm paul 打标签 列出标签 git tag 搜索查找 git tag -l ’v1.8.5*‘ 标签类型 轻量标签 很像一个不会改变的分支-它知识一个特定提交的引用 附注标签 时存储再git数据库中的一个完整对象，他们可以被校验的：其中包括打标签者的名字、电子邮件地址、日期时间；还有一个标签信息；并且可以使用GUN Privacy Guard(GPG)签名与验证 创建附注标签 git tag -a v1.4 -m ‘my version 1.4’ -m 选项指定一个将会存储再标签中的信息 git show v1.4 查看提交信息 创建轻量标签 git tag v1.4 后期打标签 可以对过去的提交打标签 查看log， git log —pretty=online git tag -a v1.2 [校验和，也就是commentId] 共享标签 默认情况下，git push 命令不会传送标签到远程仓库服务器上 git push origin [tagname] 一次性推送很多标签 git push origin \u0026ndash; tags 检出标签 git checkout -b [branchname] [tagname]7887 示例：git checkout -b version2 v2.0.0 Git 别名 git config \u0026ndash;global alias.co checkout git config —global alias.ci commit 当输入git commit时，只需要输入git ci 为解决取消暂存文件的易用性问题，可以向Git添加自己的取消暂存别名： git config —global alias.unstage ‘reset HEAD —’ 这会使下面的两个命令等价： git unstage fileA git reset HEAD — fileA 如果想要执行外部命令，需要在命令前面加入！符号 git config —global alias.visual ‘!gitk’ Git 分支 查看各个分支当前所指的对象 git log —oneline —decorate 切换分支 git checkout testing 查看分叉历史 git log —oneline —decorate —graph -all 分支的新建和合并 现在有个bug，需要修复。流程如下 创建issue分支 git checkout - b iss53 提交了修复代码 线上有个紧急问题 git checkout master git checkout - b hotfix 修改提交 运行测试 git checkout master git merge hotfix fast-forward ，由于当前master分支所指向的提交是你当前提交的直接上游，所以git只是简单的将指针向前移动。 git branch -d hotfix git checkout iss53 如果想要hotfix的修改，可以git merge master 分支管理 获取当前分支列表 git branch *代表现在检出的那一个分支 查看每一个分支最后的提交 git branch -v 查看哪些分支已经合并到当前分支 git branch —merged 删除分支 git branch -d 强制删除 git branch -D 查看所有包含未合并工作的分支 git branch —no-merged 分支开发工作流程 显示的获取远程引用的完整列表 git ls-remote git remote show [仓库名] 获得远程分支的更多信息 创建分支 正常的：git checkout -b [branch] [remotename]/[branch] 快捷方式：git checkout —track origin/serverfix 修改上游分支 git branch -u origin/serverfix 查看设置的所有跟踪分支 git branch -vv 更新仓库数据 git fetch —all 删除远程分支 git push origin —delete serverfix 合并 merge 与 rebase，这两种整合方法的最终结果没有任何区别，但是rebase使得提交历史中更加整洁。你在查看一个经过rebase的分支历史记录时会发现，尽管实际的开发工作时并行的，但它们看上去就像时先后串行的一样，提交历史是一条直线没有分叉 无论通过rebase还是第三方合并，整合的最终结果所指向的快照始终时一样的，只不过提交历史不同罢了。rebase是将一系列提交按照原有次序依次应用到另一分支上，而合并是最终结果合在一起。 有趣的rebase 例子 创建分支server，提交C3,C4 从C3创建特性分支client，提交C8,C9 回到server分支，提交C10 假设你希望将client中的修改合并到主分支并发布，但暂时并不想合并server中的修改，因为它们还需要经过更全面的测试 git rebase —onto master server client 这个意思是，把client与server的共同祖先合并 git checkout master git merge client server也合并master git rebase master server rebase的风险 不要对在你的仓库外有副本的分支执行rebase 如果别人，push后，又 重新rebase，需要使用这个命令 git pull —rebase 相当于：git fetch , git rebase master 总的原则，只对尚未推送或分享给别人的本地修改执行rebase操作清理历史，从不对已推送至别处的提交执行rebase操作，这样，你才能享受到两种方式带来的便利 提交准则 空白错误检查 git diff —check 暂存文件 git add —patch 优质提交信息的习惯会使Git的使用与协作容易的多 向一个项目贡献 带上-u 参数其实就相当于记录了push到远端分支的默认值，这样当下次我们还想要继续push的这个远端分支的时候推送命令就可以简写成git push即可。 git push -u origin featureA -u 是 —set-upstream的简写，该标记为之后轻松地推送和拉去配置分支 推送远程分支,featureB是本地分支，featureBee是远程分支 git push -u origin featureB:featureBee 日志过滤器，要i求Git只显示所有在后面分支，但不在前面分支的提交列表 git log issue54..origin/master 另一个例子：git log featureA..origin/featureA 没有合并日志git log —no-merge issue54..origin/master 派生的公开项目 合并修改 先把目标克隆到本地 提交修改 github上，fork目标项目到自己账号下 添加自己的远程仓库地址，git remote add myfork (url) git push -u myfork featureA 发送拉去请求 —squash 选项接受被合并的分支上的所有工作，并将其压缩至一个变更集，是仓库变成一个真正的合并的状态，而不会真的生成一个合并提交 —no-commit 选项在默认合并过程中可以用来延迟生成合并提交 维护项目 应用邮件补丁 使用apply命令应用补丁 git apply /temp/patch-ruby-client.patch git apply 与 patch -p1 命令来应用补丁几乎是等效的，但这种方式更严格。 git apply命令采用了一种“全部应用，否则全部撤销” 可以使用git apply 来检查补丁是否可以顺利应用 git apply —check xxx.patch 使用am命令应用补丁 找到分支的共同祖先 git merge-base contrib master git diff master..contrib 该命令仅会显示自当前特性分支与master分支的共同祖先起，该分支中的工作。 另一种将引入的工作转移到其他分支的方法是拣选。 git cherry-pick [git commit id] 为发布打标签 git tag -s v1.5 -m ‘my signed 1.5 tag’ 快照归档 git archive master —prefix=’project/’ | gzip \u0026gt; ‘git describe master’.tar.gz 制作提交简报 git shortlog —no-merges mater —not v1.0.1 ","permalink":"https://omgkill.github.io/post/git/git%E7%9A%84%E4%BD%BF%E7%94%A8/","tags":["git"],"title":"git 使用"},{"categories":null,"contents":"wiki.js 安装搜索 整体安装，参考 https://www.bilibili.com/read/cv16951722/ 参考安装ElasticSearch https://zhuanlan.zhihu.com/p/257867352 安装好后，需要rebuild Note that if you already have content in your wiki, you must click on Rebuild Index afterwards to import all your existing content into the search engine. Any change (new, edit, delete page) will be handled automatically from this point forward.\nYour content here\n","permalink":"https://omgkill.github.io/post/wiki/wiki%E6%90%9C%E7%B4%A2/","tags":["wiki.js"],"title":"wiki搜索"},{"categories":null,"contents":" windows系统要求 系统是专业版 系统版本号Windows10 2018 April（Windows 1803）及以上版本 安装需要的功能 打开控制面板 -\u0026gt; 搜索启动或关闭Windows功能 -\u0026gt; 选择以下功能 -\u0026gt; 点击确定 -\u0026gt; 安装 -\u0026gt; 重启 更新wsl2 下载安装 https://wslstorestorage.blob.core.windows.net/wslblob/wsl_update_x64.msi 在管理员下执行命令 wsl \u0026ndash;set-default-version 2 需要更多的设置参考 https://docs.microsoft.com/zh-cn/windows/wsl/setup/environment https://docs.microsoft.com/zh-cn/windows/wsl/tutorials/gui-apps https://docs.microsoft.com/en-us/windows/wsl/install-manual 更新wsl2内核 - 在管理员下执行命令 更新：wsl \u0026ndash;update 重启：wsl \u0026ndash;shutdown 安装centos7子系统 下载地址，对应centos7 https://github.com/wsldl-pg/CentWSL/releases/ 解压到指定目录 点击centos7.exe,会自动安装 完成后，我们查看当前子系统 命令行下执行：wsl -l -v 设置centos7为默认子系统 wslconfig /s CentOS7 wsl 进入centos7,查看系统信息 cat /etc/redhat-release 目前为止，windows下linux子系统已安装完成，接下连安装docker docker 下载地址 https://www.docker.com/get-started/ 选择wsl2安装 安装完成后，需要改的配置 加仓库地址 docker也安装完成 启动docker命令 需要把服id（SERVER_ID）改为自己的服id 1docker run -d --privileged --rm --name game -h game -v C:\\Users\\Administrator\\Desktop\\td\\ClashOfKingProject:/home/ams2/ClashOfKingProject --env SERVER_ID=11 -p 8080:8080 -p 8088:8088 -p 8788:8788 -v redis_data:/home/elex/redis/data 10.0.3.2:5001/developer/game 兼容的模拟器 下载地址 https://www.bluestacks.com/download.html ps：windows 下 docker与wsl占用内存太高了，不建议用 ","permalink":"https://omgkill.github.io/post/docker/windows%E5%B9%B3%E5%8F%B0%E4%BD%BF%E7%94%A8docker%E5%90%AF%E5%8A%A8%E6%B5%8B%E8%AF%95%E6%9C%8D/","tags":["windows","docker"],"title":"windows平台使用docker启动测试服"},{"categories":null,"contents":"部署WIKI.js wiki的介绍地址\nhttps://sspai.com/post/78945 wiki 的docker compose文件,文件名：docker-compose.yml\n1version: \u0026#34;3\u0026#34; 2services: 3 4 db: 5 image: postgres:11-alpine 6 environment: 7 POSTGRES_DB: wiki 8 POSTGRES_PASSWORD: wikijsrocks 9 POSTGRES_USER: wikijs 10 logging: 11 driver: \u0026#34;none\u0026#34; 12 restart: unless-stopped 13 volumes: 14 - db-data:/var/lib/postgresql/data 15 16 wiki: 17 image: ghcr.io/requarks/wiki:2 18 depends_on: 19 - db 20 environment: 21 DB_TYPE: postgres 22 DB_HOST: db 23 DB_PORT: 5432 24 DB_USER: wikijs 25 DB_PASS: wikijsrocks 26 DB_NAME: wiki 27 restart: unless-stopped 28 ports: 29 - \u0026#34;80:3000\u0026#34; 30 31volumes: 32 db-data: 安装docker\nyum install -y docker 安装docker compose\ncurl -L https://github.com/docker/compose/releases/download/1.23.1/docker-compose-`uname -s-uname -m` \u0026gt; /usr/local/bin/docker-compose chmod +x /usr/local/bin/docker-compose curl -L https://raw.githubusercontent.com/docker/compose/1.29.1/contrib/completion/bash/docker-compose \u0026gt; /etc/bash_completion.d/docker-compose 存储选择git\n需要去docker里生成ssh key 选择ssh类型的github 仓库地址 报错1:Cannot connect to the Docker daemon at unix:///var/run/docker.sock\nmv /usr/bin/systemctl /usr/bin/systemctl.old curl https://raw.githubusercontent.com/gdraheim/docker-systemctl-replacement/master/files/docker/systemctl.py \u0026gt; /usr/bin/systemctl chmod +x /usr/bin/systemctl 在cmd下， wsl \u0026ndash;shutdown 在cmd下， wsl 启动服务\nservice docker start docker-compose up -d 报错2:wsl Cannot start service db: oci runtime error: systemd cgroup flag passed, but systemd support for mana\n1I just performed the following steps, and it appears that the error has disappeared. FYI. 2 3Re-enable Hyper-V and restart the computer. 4Edit (or create) the file /etc/wsl.conf in WSL, and add the follow lines: 5[boot] 6systemd=true 7Run wsl --shutdown as an administrator in PowerShell to close the WSL instance, and then restart WSL. 8After logging back into WSL, I found that the systemctl command could be used properly and the error had disappeared. At the moment, my Docker seems to be running well. - 参考：https://github.com/microsoft/WSL/issues/9868 ","permalink":"https://omgkill.github.io/post/wiki/%E5%88%9B%E5%BB%BAwiki.js/","tags":["wiki","blob"],"title":"创建wiki.js"},{"categories":["game"],"contents":"TL-1.27 解析/验证/发货\nsql表 pay_request的意义 玩家开始支付的时间 打点，可知玩家想买哪些，但最终没买 玩家购买信息，比如礼包，挡位，等等. 当回调数据不对，比如 实际支付的挡位和发货礼包挡位不一致，这个怎么处理 比如玩家购买折扣礼包，显示的低，但回调的挡位高 比如玩家购买，支付平台打折，导致，礼包挡位高，但回调挡位低 我们应该怎么处理呢，以哪个为准呢。 订单log 数据太多了 支付流程\n客户端请求 请求流程\n线程锁\n解析参数\n白名单 解密 验证了金额 兑换码 验证参数\n给的一个字符串，和自己用key加密的字符串，判断是否一致 订单是否已存在\n更新支付数据\n代充处理jira\nAMS-31030 【运营】IOS代充方案处理\nAMS-39212 当前玩家的设备ID和注册的设备ID一致，不计入代充\nAMS-50928 iOS沙盒测试的开关改造，可以指定渠道及版本\n需要做的功能\n参数验证,/密钥验证/请求验证 发货 退款过多封号（监控） 扣除玩家装备 支付前有支付动作 定一下流程\n客户发起支付 玩家下单 苹果回调 客户端回调服务器发货 服务器验证，并发货 要哪些数据库表\n历史记录数据\npayRequest请求\n1CREATE TABLE `pay_request` ( 2 `uid` varchar(40) COLLATE utf8_unicode_ci NOT NULL, 3 `pf` varchar(20) COLLATE utf8_unicode_ci NOT NULL, 4 `time` bigint(20) NOT NULL, 5 `purchaseId` varchar(10) COLLATE utf8_unicode_ci DEFAULT \u0026#39;\u0026#39;, 6 `productId` varchar(10) COLLATE utf8_unicode_ci DEFAULT \u0026#39;\u0026#39;, 7 `status` int(4) DEFAULT \u0026#39;0\u0026#39;, 8 `finishTime` bigint(20) DEFAULT \u0026#39;0\u0026#39;, 9 PRIMARY KEY (`uid`,`pf`,`time`), 10 KEY `index_uid_pf_productId` (`uid`,`pf`,`purchaseId`), 11 KEY `index_uid_pf_purchaseId` (`uid`,`pf`,`purchaseId`) 12) ENGINE=InnoDB DEFAULT CHARSET=utf8 COLLATE=utf8_unicode_ci 订单数据,global db\n1 CREATE TABLE `exchange` ( 2 `orderId` varchar(200) COLLATE utf8_unicode_ci NOT NULL, 3 `pf` varchar(20) COLLATE utf8_unicode_ci NOT NULL, 4 PRIMARY KEY (`pf`,`orderId`) 5 ) ENGINE=InnoDB DEFAULT CHARSET=utf8 COLLATE=utf8_unicode_ci 支付失败/支付log\n1 CREATE TABLE `paylog` ( 2 `uid` varchar(40) COLLATE utf8_unicode_ci NOT NULL COMMENT \u0026#39;玩家uid\u0026#39;, 3 `pay_type` int(5) NOT NULL DEFAULT \u0026#39;0\u0026#39; COMMENT \u0026#39;支付类型\u0026#39;, 4 `order_id` varchar(200) COLLATE utf8_unicode_ci NOT NULL COMMENT \u0026#39;订单id\u0026#39;, 5 `pf` varchar(20) COLLATE utf8_unicode_ci NOT NULL COMMENT \u0026#39;渠道\u0026#39;, 6 `product_id` varchar(10) COLLATE utf8_unicode_ci NOT NULL DEFAULT \u0026#39;0\u0026#39; COMMENT \u0026#39;挡位id\u0026#39;, 7 `transaction_id` varchar(200) COLLATE utf8_unicode_ci DEFAULT NULL COMMENT \u0026#39;交易id\u0026#39;, 8 `goods_id` varchar(10) COLLATE utf8_unicode_ci NOT NULL DEFAULT \u0026#39;0\u0026#39; COMMENT \u0026#39;物品id\u0026#39;, 9 `time` bigint(20) NOT NULL DEFAULT \u0026#39;0\u0026#39; COMMENT \u0026#39;购买时间\u0026#39;, 10 `currency` int(10) NOT NULL DEFAULT \u0026#39;0\u0026#39; COMMENT \u0026#39;货币类型\u0026#39;, 11 `spend` double(10,2) NOT NULL DEFAULT \u0026#39;0.00\u0026#39; COMMENT \u0026#39;花费货币数量\u0026#39;, 12 `paid` double(10,2) NOT NULL DEFAULT \u0026#39;0.00\u0026#39; COMMENT \u0026#39;实际支付金额\u0026#39;, 13 `status` int(4) NOT NULL DEFAULT \u0026#39;0\u0026#39; COMMENT \u0026#39;购买状态\u0026#39;, 14 PRIMARY KEY (`uid`,`order_id`,`pf`), 15 KEY `index_time_pf` (`time`,`pf`) 16 ) ENGINE=InnoDB DEFAULT CHARSET=utf8 COLLATE=utf8_unicode_ci 1 CREATE TABLE `paylog` ( 2 `uid` varchar(40) COLLATE utf8_unicode_ci NOT NULL, 3 `orderId` varchar(200) COLLATE utf8_unicode_ci NOT NULL, 4 `pf` varchar(20) COLLATE utf8_unicode_ci NOT NULL, 5 `productId` varchar(10) COLLATE utf8_unicode_ci NOT NULL DEFAULT \u0026#39;0\u0026#39;, 6 `orderInfo` varchar(200) COLLATE utf8_unicode_ci DEFAULT NULL, 7 `orderParam` blob, 8 `order_items` varchar(500) COLLATE utf8_unicode_ci DEFAULT \u0026#39;{}\u0026#39; COMMENT \u0026#39;订单获得的物品\u0026#39;, 9 `purchase_token` varchar(200) COLLATE utf8_unicode_ci DEFAULT NULL COMMENT \u0026#39;订单token\u0026#39;, 10 `sku` varchar(10) COLLATE utf8_unicode_ci DEFAULT NULL COMMENT \u0026#39;订单sku\u0026#39;, 11 `time` bigint(20) DEFAULT NULL, 12 `currency` int(10) DEFAULT \u0026#39;0\u0026#39;, 13 `spend` double(10,2) NOT NULL DEFAULT \u0026#39;0.00\u0026#39;, 14 `paid` double(10,2) DEFAULT \u0026#39;0.00\u0026#39;, 15 `status` int(4) DEFAULT \u0026#39;0\u0026#39;, 16 `payLevel` int(10) NOT NULL, 17 `buildingLv` int(11) DEFAULT NULL, 18 `receiverId` varchar(40) COLLATE utf8_unicode_ci DEFAULT NULL, 19 `deviceId` varchar(255) COLLATE utf8_unicode_ci DEFAULT NULL, 20 `ip` varchar(20) COLLATE utf8_unicode_ci DEFAULT \u0026#39;\u0026#39;, 21 `type` int(10) NOT NULL DEFAULT \u0026#39;0\u0026#39; COMMENT \u0026#39;用户类型,衮服,重玩,新用户\u0026#39;, 22 `vipLevel` int(10) NOT NULL DEFAULT \u0026#39;0\u0026#39; COMMENT \u0026#39;支付时候的VIP等级\u0026#39;, PRIMARY KEY (`uid`,`orderId`,`pf`) USING BTREE, 23 KEY `index_time_pf` (`time`,`pf`) USING BTREE 24 ) ENGINE=InnoDB DEFAULT CHARSET=utf8 COLLATE=utf8_unicode_ci ROW_FORMAT=COMPACT 监控支付\n1CREATE TABLE `uid_monitor_device` ( 2 `uid` varchar(255) COLLATE utf8_unicode_ci NOT NULL DEFAULT \u0026#39;\u0026#39;, 3 `devices` varchar(1024) CHARACTER SET utf8 COLLATE utf8_bin NOT NULL DEFAULT \u0026#39;\u0026#39; COMMENT \u0026#39;设备Id，逗号分隔,最多60个\u0026#39;, 4 `pay_times` int(10) NOT NULL DEFAULT \u0026#39;0\u0026#39; COMMENT \u0026#39;付费次数\u0026#39;, 5 `create_time` bigint(20) DEFAULT \u0026#39;0\u0026#39; COMMENT \u0026#39;记录创建时间\u0026#39;, 6 `update_time` bigint(20) DEFAULT \u0026#39;0\u0026#39; COMMENT \u0026#39;记录修改时间\u0026#39;, 7 `devices_history` text COLLATE utf8_unicode_ci COMMENT \u0026#39;ban设备历史 实际[设备id]\u0026#39;, 8 PRIMARY KEY (`uid`) 9) ENGINE=InnoDB DEFAULT CHARSET=utf8 COLLATE=utf8_unicode_ci ","permalink":"https://omgkill.github.io/post/game/tlrecord/","tags":["game","record"],"title":"TL Record"},{"categories":["代码优化"],"contents":"代码解决方案\n1. 问题：逻辑有点复杂，还要在复杂的逻辑上修改 - 解决方案： - 1. 改动小，代码执行是没问题。但不容易理解 - 2. 改动大，代码是解构的。更容易理解 - 最终解决 - 选择的方案2 - 原因： - 结构清晰，更容易理解 - reviewer也更容易看明白，确保没有问题 2. 问题：leader希望复用共同的逻辑，但配置却是独立的，没有用共同的。同时配置又深入嵌入到逻辑的各处 - leader希望的 - 复用共同逻辑，可以用模板方法解决 - 我一开始的做法 - 只共用一个接口，逻辑代码是copy的 - 这样就又冲突了。 - 最后方案 - 使用适配器模式，通过一个配置类关联两个独立的配置 - 这样底层的配置读取就是共同的，不需要做特殊处理。后续相关的活动也可以这样处理 - 创建一个stage类，然后再创建stageGc类并继承stage。同时一个配置解析类 ","permalink":"https://omgkill.github.io/post/codeoptimize/%E4%BB%A3%E7%A0%81%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/","tags":["代码解决方案"],"title":"一些共同场景问题解决方式"},{"categories":["docker"],"contents":"ams2 压测服game服务容器化 由于压测都是找空闲的机器来测试，所以每次压测都要重新部署环境，为了简化流程，想通过docker简化操作\n参考lost私服做的修改\nlost私服:http://confluence.super-chameleon.com:8093/pages/viewpage.action?pageId=75476077 文件路径\nhttp://svn.super-chameleon.com:8822/svn/AMS_TD/Source/trunk/Server/Tools/Ops/ds 使用jenkins构建docker镜像\njenkins地址：http://10.0.3.2:7005/ 使用nexus3作为docker镜像仓库\n仓库地址：http://10.0.3.2:8082/ docker 管理界面\n地址：http://10.0.3.2:9000/ 关于base的构建\nbase的意思是搭建一个基础环境\n包含cetos7、jdk安装、mysql安装、redis安装、ssh安装\njenkins构建base\n进入jenkins界面，点击build_ams2_base\n​\n再点击立即构建，就会自动编译，并编译推送到仓库\njenkins配置：http://svn.super-chameleon.com:8822/svn/AMS_TD/Source/trunk/Server/Tools/Ops/ds/jenkins/build_ams2_base.jenkins\ndockerfile以及其他文件：http://svn.super-chameleon.com:8822/svn/AMS_TD/Source/trunk/Server/Tools/Ops/ds/docker/base\n关于ams2的构建\n这个就是真正构建game服务 包含redis启动、mysql启动、mysql数据导入、game部署文件、game启动 jenkins构建base 进入jenkins界面，点击build_ams2_ds 再点击立即构建，就会自动编译，并编译推送到仓库 jenkins配置：http://svn.super-chameleon.com:8822/svn/AMS_TD/Source/trunk/Server/Tools/Ops/ds/jenkins/build_ams2_ds.jenkins dockerfile以及其他文件：http://svn.super-chameleon.com:8822/svn/AMS_TD/Source/trunk/Server/Tools/Ops/ds/docker/ams2 说一下build_ams2_base 这个任务如何创建的。build_ams2_ds同理\n点击新建任务， 输入任务名字，点击流水线，再点击报错 填写描述，点击不允许并发构建 按照如下配置，Credentials是svn的账号密码 还有一个脚本路径，这个是相对路径。相对于svn down的目录 点击保存就好了_ ","permalink":"https://omgkill.github.io/post/docker/game%E6%9C%8D%E5%8A%A1%E5%AE%B9%E5%99%A8%E5%8C%96/","tags":["docker","网络"],"title":"ams2 压测服game服务容器化"},{"categories":["docker"],"contents":" gm服部署nexus3，这个用于docker image 仓库。 参考：http://confluence.super-chameleon.com:8093/pages/viewpage.action?pageId=75479441 gm服部署jenkins 参考：http://confluence.super-chameleon.com:8093/pages/viewpage.action?pageId=75479445 需要安装docker plugin 插件管理中安装Docker, 系统管理-\u0026gt;插件管理-\u0026gt; 可选插件-\u0026gt;搜索docker 配置docker镜像仓库地址和密钥，路径：系统管理-\u0026gt;系统配置-\u0026gt; Declarative Pipeline (Docker) 安装gradle plugin 配置gradle，名字：gradle564，版本：Gradle 5.6.4，路径：系统管理-\u0026gt;全局工具配置-\u0026gt; Gradle jenkins配置 参考：http://confluence.super-chameleon.com:8093/pages/viewpage.action?pageId=96209340 构建ams2-base 和 ams2-ds svn checkout 脚本 svn地址：http://svn.super-chameleon.com:8822/svn/AMS_TD/Source/trunk/Server/Tools/Ops/ds/deploy_stressing 进入deploy_stressing文件夹 执行脚本， 默认启动8001服 python deploy_stressing_server.py -g \u0026lt;game服内网ip\u0026gt; -d \u0026lt;mysql与clusterRedis服内网ip\u0026gt; -n \u0026lt;docker镜像仓库所在服内网ip\u0026gt; 如果要重启game服，要多加一个参数：-r python deploy_stressing_server.py -g \u0026lt;game服内网ip\u0026gt; -d \u0026lt;mysql与clusterRedis服内网ip\u0026gt; -n \u0026lt;docker镜像仓库所在服内网ip\u0026gt; -r true 脚本支持重复执行，如果脚本中途执行失败，可以重复执行 docker储存到宿主机的数据 mysql的数据存储地址，在宿主机的:/home/docker/docker/volume/stress_db_mysql redis的数据存储地址，在宿主机：/home/docker/docker/volume/stress_db_redis game log的数据存储地址，在宿主机：/home/docker/docker/volume/stress_game_log 示例 python .\\deploy_stressing_server.py -g 10.0.3.203 -d 10.0.3.21 -n 10.0.3.2 ##脚本说明\n脚本需要两台服务器。 一个台部署game与local redis，一台部署mysql与cluster redis 两台机器容器如何互联，参考：http://confluence.super-chameleon.com:8093/pages/viewpage.action?pageId=96209514 如果要删除所有docker数据，执行一下命令 yum remove -y docker* ##报错解决\n1报错解决 2 3[root@server2002 home]# docker network rm docker_gwbridge 4Error response from daemon: network docker_gwbridge has active endpoints 5 6 7 8 9[root@server2002 home]# docker network inspect docker_gwbridge 10[ 11 { 12 \u0026#34;Name\u0026#34;: \u0026#34;docker_gwbridge\u0026#34;, 13 \u0026#34;Id\u0026#34;: \u0026#34;0eecc7be54a618d305be26b9081998437529e5dace05c71b538da63611509cc3\u0026#34;, 14 \u0026#34;Created\u0026#34;: \u0026#34;2022-04-24T07:35:29.709419174Z\u0026#34;, 15 \u0026#34;Scope\u0026#34;: \u0026#34;local\u0026#34;, 16 \u0026#34;Driver\u0026#34;: \u0026#34;bridge\u0026#34;, 17 \u0026#34;EnableIPv6\u0026#34;: false, 18 \u0026#34;IPAM\u0026#34;: { 19 \u0026#34;Driver\u0026#34;: \u0026#34;default\u0026#34;, 20 \u0026#34;Options\u0026#34;: null, 21 \u0026#34;Config\u0026#34;: [ 22 { 23 \u0026#34;Subnet\u0026#34;: \u0026#34;172.19.0.0/16\u0026#34;, 24 \u0026#34;Gateway\u0026#34;: \u0026#34;172.19.0.1\u0026#34; 25 } 26 ] 27 }, 28 \u0026#34;Internal\u0026#34;: false, 29 \u0026#34;Attachable\u0026#34;: false, 30 \u0026#34;Containers\u0026#34;: { 31 \u0026#34;f32013a3de270374e0baf8e030e7182f0a75024a796b2459e703f15deeb48725\u0026#34;: { 32 \u0026#34;Name\u0026#34;: \u0026#34;gateway_f32013a3de27\u0026#34;, 33 \u0026#34;EndpointID\u0026#34;: \u0026#34;376c39efa00c1cd178d27f5daec7ffcb0ed06f71db8e15bab66834bb438342a2\u0026#34;, 34 \u0026#34;MacAddress\u0026#34;: \u0026#34;02:42:ac:13:00:02\u0026#34;, 35 \u0026#34;IPv4Address\u0026#34;: \u0026#34;172.19.0.2/16\u0026#34;, 36 \u0026#34;IPv6Address\u0026#34;: \u0026#34;\u0026#34; 37 } 38 }, 39 \u0026#34;Options\u0026#34;: { 40 \u0026#34;com.docker.network.bridge.enable_icc\u0026#34;: \u0026#34;false\u0026#34;, 41 \u0026#34;com.docker.network.bridge.enable_ip_masquerade\u0026#34;: \u0026#34;true\u0026#34;, 42 \u0026#34;com.docker.network.bridge.name\u0026#34;: \u0026#34;docker_gwbridge\u0026#34; 43 }, 44 \u0026#34;Labels\u0026#34;: {} 45 } 46] 47 48docker network disconnect -f docker_gwbridge gateway_def4bf4c78ab 49 50docker network rm docker_gwbridge ","permalink":"https://omgkill.github.io/post/docker/%E4%BD%BF%E7%94%A8docker%E5%90%AF%E5%8A%A8%E5%8E%8B%E6%B5%8B%E6%9C%8D/","tags":["docker","nexus3","jenkins","压测"],"title":"使用Docker启动压测服"},{"categories":["docker"],"contents":"#Docker 跨主机容器通信实践\nDockerOverlay网络\nOverlay是一种覆盖在主机上的虚拟网络，我理解的overlay他需要借助插件或工具完成对数据的保存和转发。我们这里使用etcd来完成overlay的跨主机容器通信 本文以两台机器为例，ip分配是 10.0.3.2 与 10.0.3.21\n检查两台机器hostname是否不同，如果相同需要修改。不然无法联通\n两台机器安装docker\nyum install -y docker 修改docker配置,指定外部存储使用etcd，/etc/docker/daemon.json 加如下数据\n主机10.0.3.2 \u0026ldquo;cluster-store\u0026rdquo;:\u0026ldquo;etcd://10.0.3.2:2379\u0026rdquo;,\u0026ldquo;cluster-advertise\u0026rdquo;:\u0026ldquo;10.0.3.2:2375\u0026rdquo; 主机10.0.3.21 \u0026ldquo;cluster-store\u0026rdquo;:\u0026ldquo;etcd://10.0.3.21:2379\u0026rdquo;,\u0026ldquo;cluster-advertise\u0026rdquo;:\u0026ldquo;10.0.3.21:2375\u0026rdquo; 重启docker\nsystemctl daemon-reload systemctl restart docker 启动etcd\n主机10.0.3.2, etcd节点名为node1 1 docker run -d --name etcd --rm \\ 2 --publish 2379:2379 \\ 3 --publish 2380:2380 \\ 4 --env ALLOW_NONE_AUTHENTICATION=yes \\ 5 --env ETCD_NAME=node1 \\ 6 --env ETCD_LISTEN_PEER_URLS=http://0.0.0.0:2380 \\ 7 --env ETCD_ADVERTISE_CLIENT_URLS=http://10.0.3.2:2379 \\ 8 --env ETCD_LISTEN_CLIENT_URLS=http://0.0.0.0:2379 \\ 9 --env ETCD_INITIAL_ADVERTISE_PEER_URLS=http://10.0.3.2:2380 \\ 10 --env ETCD_INITIAL_CLUSTER_TOKEN=etcd-cluster \\ 11 --env ETCD_INITIAL_CLUSTER=node1=http://10.0.3.2:2380,node2=http://10.0.3.21:2380 \\ 12 --env ETCD_INITIAL_CLUSTER_STATE=new \\ 13 bitnami/etcd:3.5.3 etcd --enable-v2 主机10.0.3.21, etcd节点名为node1 1docker run -d --name etcd --rm \\ 2--publish 2379:2379 \\ 3--publish 2380:2380 \\ 4--env ALLOW_NONE_AUTHENTICATION=yes \\ 5--env ETCD_NAME=node2 \\ 6--env ETCD_LISTEN_PEER_URLS=http://0.0.0.0:2380 \\ 7--env ETCD_ADVERTISE_CLIENT_URLS=http://10.0.3.21:2379 \\ 8--env ETCD_LISTEN_CLIENT_URLS=http://0.0.0.0:2379 \\ 9--env ETCD_INITIAL_ADVERTISE_PEER_URLS=http://10.0.3.21:2380 \\ 10--env ETCD_INITIAL_CLUSTER_TOKEN=etcd-cluster \\ 11--env ETCD_INITIAL_CLUSTER=node1=http://10.0.3.2:2380,node2=http://10.0.3.21:2380 \\ 12--env ETCD_INITIAL_CLUSTER_STATE=new \\ 13bitnami/etcd:3.5.3 etcd --enable-v2 查看etcd node\n1[root@ams2-10 ~]# docker exec -it etcd etcdctl member list 2796e13f38b3a972b, started, node2, http://10.0.3.21:2380, http://10.0.3.21:2379, false 3ff63796d3826f6b6, started, node1, http://10.0.3.2:2380, http://10.0.3.2:2379, false 创建overlay network\n主机10.0.3.2\n1 [root@ams2-10 SFS2X]# docker network create -d overlay etcdnet 2 f2c12e0259409c0f11c9c4a4a585753d46a80ac60c336625fd48e5322be9084e 查看网络，发现多了刚刚创建的etcdnet.而且scope是global的 1 [root@ams2-10 SFS2X]# docker network ls 2 NETWORK ID NAME DRIVER SCOPE 3 f406ad6eb59c bridge bridge local 4 f2c12e025940 etcdnet overlay global 5 097d3b78ec65 host host local 6 02d4e89d5af5 none null local 我们inspect下etcdnet信息 1 [root@ams2-10 SFS2X]# docker network inspect etcdnet 2 [ 3 { 4 \u0026#34;Name\u0026#34;: \u0026#34;etcdnet\u0026#34;, 5 \u0026#34;Id\u0026#34;: \u0026#34;f2c12e0259409c0f11c9c4a4a585753d46a80ac60c336625fd48e5322be9084e\u0026#34;, 6 \u0026#34;Created\u0026#34;: \u0026#34;2022-04-18T14:18:10.96517192Z\u0026#34;, 7 \u0026#34;Scope\u0026#34;: \u0026#34;global\u0026#34;, 8 \u0026#34;Driver\u0026#34;: \u0026#34;overlay\u0026#34;, 9 \u0026#34;EnableIPv6\u0026#34;: false, 10 \u0026#34;IPAM\u0026#34;: { 11 \u0026#34;Driver\u0026#34;: \u0026#34;default\u0026#34;, 12 \u0026#34;Options\u0026#34;: {}, 13 \u0026#34;Config\u0026#34;: [ 14 { 15 \u0026#34;Subnet\u0026#34;: \u0026#34;10.0.0.0/24\u0026#34;, 16 \u0026#34;Gateway\u0026#34;: \u0026#34;10.0.0.1\u0026#34; 17 } 18 ] 19 }, 20 \u0026#34;Internal\u0026#34;: false, 21 \u0026#34;Attachable\u0026#34;: false, 22 \u0026#34;Containers\u0026#34;: {}, 23 \u0026#34;Options\u0026#34;: {}, 24 \u0026#34;Labels\u0026#34;: {} 25 } 26 ] 主机10.0.3.21\n查看网络，发现也有etcdnet了，也就是说一个主机创建，同集群下的主机都会自动创建 1 [root@ams2-10 ~]# docker network ls 2 NETWORK ID NAME DRIVER SCOPE 3 3ed479747a1e bridge bridge local 4 f2c12e025940 etcdnet overlay global 5 4097f7659809 host host local 6 e72e71890e1a none null local 开启一个redis服务\n主机 10.0.3.2 1 [root@ams2-10 SFS2X]# docker run -d --rm --name redis1 -h redis1 --net etcdnet 10.0.3.2:5001/base_redis 2 8769e01b7003bb42edf226c812405a2e955fb0e16fae0752c37a703efdcc2135 主机10.0.3.21 尝试也创建一个docker name为redis1的容器. 1 [root@ams2-10 ~]# docker run -d --rm --name redis1 -h redis1 --net etcdnet 10.0.3.2:5001/base_redis 2 9499adbbce469022ec1bef41415d58398fa79bc1a155316a07182f0278657a4d 3 /usr/bin/docker-current: Error response from daemon: service endpoint with name redis1 already exists. 报错了，也就是不能创建相同name的容器。我们起一个name为redis2的容器 1 [root@ams2-10 ~]# docker run -d --rm --name redis2 -h redis2 --net etcdnet 10.0.3.2:5001/base_redis 2 fea93e725e69f01ffa2e5431d470e230aa8496d8a9106a10ea738c0ff411e340 查看网络信息\n主机 10.0.3.2 运行docker network ls，多了一个docker_gwbridge，看下这个网络容器的详情信息 1 [root@ams2-10 SFS2X]# docker inspect docker_gwbridge 2 [ 3 { 4 \u0026#34;Name\u0026#34;: \u0026#34;docker_gwbridge\u0026#34;, 5 \u0026#34;Id\u0026#34;: \u0026#34;d56f9aef3da6f93cc2749efcdace3265bb29150f145041e4d736e3928fd4e363\u0026#34;, 6 \u0026#34;Created\u0026#34;: \u0026#34;2022-04-18T14:34:44.715406625Z\u0026#34;, 7 \u0026#34;Scope\u0026#34;: \u0026#34;local\u0026#34;, 8 \u0026#34;Driver\u0026#34;: \u0026#34;bridge\u0026#34;, 9 \u0026#34;EnableIPv6\u0026#34;: false, 10 \u0026#34;IPAM\u0026#34;: { 11 \u0026#34;Driver\u0026#34;: \u0026#34;default\u0026#34;, 12 \u0026#34;Options\u0026#34;: null, 13 \u0026#34;Config\u0026#34;: [ 14 { 15 \u0026#34;Subnet\u0026#34;: \u0026#34;172.18.0.0/16\u0026#34;, 16 \u0026#34;Gateway\u0026#34;: \u0026#34;172.18.0.1\u0026#34; 17 } 18 ] 19 }, 20 \u0026#34;Internal\u0026#34;: false, 21 \u0026#34;Attachable\u0026#34;: false, 22 \u0026#34;Containers\u0026#34;: { 23 \u0026#34;d0ffff5fdc19975d8930e25438b1e03f7a960f5387dc5a577e02c89809be0d62\u0026#34;: { 24 \u0026#34;Name\u0026#34;: \u0026#34;gateway_d0ffff5fdc19\u0026#34;, 25 \u0026#34;EndpointID\u0026#34;: \u0026#34;e90ebc5c48f17d5e64bdcf442173617d0b35ed81af33a901a3ae8a75a7d11a55\u0026#34;, 26 \u0026#34;MacAddress\u0026#34;: \u0026#34;02:42:ac:12:00:02\u0026#34;, 27 \u0026#34;IPv4Address\u0026#34;: \u0026#34;172.18.0.2/16\u0026#34;, 28 \u0026#34;IPv6Address\u0026#34;: \u0026#34;\u0026#34; 29 } 30 }, 31 \u0026#34;Options\u0026#34;: { 32 \u0026#34;com.docker.network.bridge.enable_icc\u0026#34;: \u0026#34;false\u0026#34;, 33 \u0026#34;com.docker.network.bridge.enable_ip_masquerade\u0026#34;: \u0026#34;true\u0026#34;, 34 \u0026#34;com.docker.network.bridge.name\u0026#34;: \u0026#34;docker_gwbridge\u0026#34; 35 }, 36 \u0026#34;Labels\u0026#34;: {} 37 } 38 ] 我们再看下 etcdnet详情, 可以看到给两个容器分配了ip 1 [root@ams2-10 SFS2X]# docker network inspect etcdnet 2 [ 3 { 4 \u0026#34;Name\u0026#34;: \u0026#34;etcdnet\u0026#34;, 5 \u0026#34;Id\u0026#34;: \u0026#34;f2c12e0259409c0f11c9c4a4a585753d46a80ac60c336625fd48e5322be9084e\u0026#34;, 6 \u0026#34;Created\u0026#34;: \u0026#34;2022-04-18T14:18:10.96517192Z\u0026#34;, 7 \u0026#34;Scope\u0026#34;: \u0026#34;global\u0026#34;, 8 \u0026#34;Driver\u0026#34;: \u0026#34;overlay\u0026#34;, 9 \u0026#34;EnableIPv6\u0026#34;: false, 10 \u0026#34;IPAM\u0026#34;: { 11 \u0026#34;Driver\u0026#34;: \u0026#34;default\u0026#34;, 12 \u0026#34;Options\u0026#34;: {}, 13 \u0026#34;Config\u0026#34;: [ 14 { 15 \u0026#34;Subnet\u0026#34;: \u0026#34;10.0.0.0/24\u0026#34;, 16 \u0026#34;Gateway\u0026#34;: \u0026#34;10.0.0.1\u0026#34; 17 } 18 ] 19 }, 20 \u0026#34;Internal\u0026#34;: false, 21 \u0026#34;Attachable\u0026#34;: false, 22 \u0026#34;Containers\u0026#34;: { 23 \u0026#34;d0ffff5fdc19975d8930e25438b1e03f7a960f5387dc5a577e02c89809be0d62\u0026#34;: { 24 \u0026#34;Name\u0026#34;: \u0026#34;redis1\u0026#34;, 25 \u0026#34;EndpointID\u0026#34;: \u0026#34;fbc06b25b76eb1e4475582f0eeb51d509ca72f070891140ab482d0f54a140601\u0026#34;, 26 \u0026#34;MacAddress\u0026#34;: \u0026#34;02:42:0a:00:00:02\u0026#34;, 27 \u0026#34;IPv4Address\u0026#34;: \u0026#34;10.0.0.2/24\u0026#34;, 28 \u0026#34;IPv6Address\u0026#34;: \u0026#34;\u0026#34; 29 }, 30 \u0026#34;ep-69ecc615e82eeddbd03cd27006130607e2440d2e1025978c00267c1ba2f7544b\u0026#34;: { 31 \u0026#34;Name\u0026#34;: \u0026#34;redis2\u0026#34;, 32 \u0026#34;EndpointID\u0026#34;: \u0026#34;69ecc615e82eeddbd03cd27006130607e2440d2e1025978c00267c1ba2f7544b\u0026#34;, 33 \u0026#34;MacAddress\u0026#34;: \u0026#34;02:42:0a:00:00:03\u0026#34;, 34 \u0026#34;IPv4Address\u0026#34;: \u0026#34;10.0.0.3/24\u0026#34;, 35 \u0026#34;IPv6Address\u0026#34;: \u0026#34;\u0026#34; 36 } 37 }, 38 \u0026#34;Options\u0026#34;: {}, 39 \u0026#34;Labels\u0026#34;: {} 40 } 41 ] 进入redis1容器，ifconfig看下一下 1 [root@ams2-10 SFS2X]# docker exec -it redis1 yum install -y net-tools.x86_64 2 [root@ams2-10 SFS2X]# docker exec -it redis1 ifconfig 3 eth0: flags=4163\u0026lt;UP,BROADCAST,RUNNING,MULTICAST\u0026gt; mtu 1450 4 inet 10.0.0.2 netmask 255.255.255.0 broadcast 0.0.0.0 5 inet6 fe80::42:aff:fe00:2 prefixlen 64 scopeid 0x20\u0026lt;link\u0026gt; 6 ether 02:42:0a:00:00:02 txqueuelen 0 (Ethernet) 7 RX packets 13 bytes 1034 (1.0 KiB) 8 RX errors 0 dropped 0 overruns 0 frame 0 9 TX packets 11 bytes 894 (894.0 B) 10 TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0 11 12 eth1: flags=4163\u0026lt;UP,BROADCAST,RUNNING,MULTICAST\u0026gt; mtu 1500 13 inet 172.18.0.2 netmask 255.255.0.0 broadcast 0.0.0.0 14 inet6 fe80::42:acff:fe12:2 prefixlen 64 scopeid 0x20\u0026lt;link\u0026gt; 15 ether 02:42:ac:12:00:02 txqueuelen 0 (Ethernet) 16 RX packets 7138 bytes 16361245 (15.6 MiB) 17 RX errors 0 dropped 0 overruns 0 frame 0 18 TX packets 7125 bytes 387572 (378.4 KiB) 19 TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0 20 21 lo: flags=73\u0026lt;UP,LOOPBACK,RUNNING\u0026gt; mtu 65536 22 inet 127.0.0.1 netmask 255.0.0.0 23 inet6 ::1 prefixlen 128 scopeid 0x10\u0026lt;host\u0026gt; 24 loop txqueuelen 1000 (Local Loopback) 25 RX packets 56 bytes 4827 (4.7 KiB) 26 RX errors 0 dropped 0 overruns 0 frame 0 27 TX packets 56 bytes 4827 (4.7 KiB) 28 TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0 29 30 [root@ams2-10 SFS2X]# 测试是否ping通\n主机10.0.3.2 我们ping一下redis2 的ip 和容器名，发现都可以ping通 1 [root@ams2-10 SFS2X]# docker exec -it redis1 ping -c 5 redis2 2 PING redis2 (10.0.0.3) 56(84) bytes of data. 3 64 bytes from redis2.etcdnet (10.0.0.3): icmp_seq=1 ttl=64 time=0.325 ms 4 64 bytes from redis2.etcdnet (10.0.0.3): icmp_seq=2 ttl=64 time=0.557 ms 5 64 bytes from redis2.etcdnet (10.0.0.3): icmp_seq=3 ttl=64 time=0.446 ms 6 64 bytes from redis2.etcdnet (10.0.0.3): icmp_seq=4 ttl=64 time=0.430 ms 7 64 bytes from redis2.etcdnet (10.0.0.3): icmp_seq=5 ttl=64 time=0.578 ms 8 --- redis2 ping statistics --- 9 5 packets transmitted, 5 received, 0% packet loss, time 3999ms 10 rtt min/avg/max/mdev = 0.325/0.467/0.578/0.093 ms 尝试连接redis2的服务，看到没问题 1 # 可以正常链接 2 [root@ams2-10 SFS2X]# docker exec -it redis1 /home/elex/redis/bin/redis-cli -h redis2 set m1 dd 3 OK 4 [root@ams2-10 SFS2X]# docker exec -it redis1 /home/elex/redis/bin/redis-cli -h redis2 get m1 5 \u0026#34;dd\u0026#34; 主机10.0.3.21， redis2 同样可以通过ip和容器名 ping通 ps\n查看etcd版本号 curl http://10.0.3.2:2379/versoin ","permalink":"https://omgkill.github.io/post/docker/docker-%E8%B7%A8%E4%B8%BB%E6%9C%BA%E5%AE%B9%E5%99%A8%E9%97%B4%E7%BD%91%E7%BB%9C%E9%80%9A%E4%BF%A1/","tags":["docker","网络"],"title":"Docker 跨主机容器间网络通信"},{"categories":["blob"],"contents":" sixdian Notes Hugo 使用 Jane 主题常用的一些配置 Published on: April 21, 2022 | Reading Time: 4 min | Last Modified: April 21, 2022\nhugojane配置\nHugo 下的 Jane 主题是基于 even 主题进行的重新改造，主要有以下特色：\n响应式设计 多国语言支持 支持多个 Shortcode 单独设计的标签页和分类页 支持社交网站链接 优秀的分页、目录、注脚样式 使用更快的 Chroma 代码高亮 自定义 css、js、head 支持子目录 搜索引擎优化 初始化的样式展示的元素繁多可能不太符合每个人的实际需求，我们需要对需要显示的内容样式进行修改来增强站点整体的美感。下面就介绍如何改靠自己的独特主题：\n默认情况下生成的站点部署后我我们会发现在手机上点按菜单位置无效，无法正常显示下拉菜单。我们可以按照下面的方法让菜单能在移动端正常显示。\nJane 主题移动端无法显示下拉菜单的解决方法 themes\\jane\\layouts\\partials\\scripts.html #根据路径找到这个文件,删除其中的 integrity 属性\n1\u0026lt;script type=\u0026#34;text/javascript\u0026#34; src=\u0026#34;{{ $secureJS.RelPermalink }}\u0026#34; integrity=\u0026#34;{{ $secureJS.Data.Integrity }}\u0026#34; crossorigin=\u0026#34;anonymous\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; 另外现在人们通过 RSS 客户端阅读的方式已经越来越少，Jane 主题内的 RSS 订阅图标我个人觉得太过多余不符合我追求简洁的审美观，所以也要对它进行隐藏处理。具体处理方法如下：\nJane 主题底部 RSS 订阅图标删除 ./layouts/partials/social_links.html #在 themes 文件夹下根据路径找到这个文件，删除以下代码\n1\u0026lt;!-- 2{{/* RSS icon */}} 3{{ with .Site.GetPage \u0026#34;home\u0026#34; -}} 4 {{- with .OutputFormats.Get \u0026#34;RSS\u0026#34; -}} 5 \u0026lt;a href=\u0026#34;{{ .Permalink }}\u0026#34; rel=\u0026#34;noopener {{ .Rel }}\u0026#34; type=\u0026#34;{{ .MediaType.Type }}\u0026#34; 6 class=\u0026#34;iconfont\u0026#34; title:\u0026#34;rss\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt; 7 {{ partial \u0026#34;svg/rss.svg\u0026#34; }} 8 \u0026lt;/a\u0026gt; 9 {{ end -}} 10{{- end -}} 11--\u0026gt; 其它需要设置的细节内容过多，而且过于简单，下面统一做个总结：\nJane 主题配置文件详细解释 1# 基础设置 2#------------------------------------------------------------------- 3baseURL = \u0026#34;https://sixdian.com/\u0026#34; # 博客部署网址 4title: \u0026#34;六点随记\u0026#34; # 网站名称 5enableRobotsTXT = true # 是否支持Robots协议 6enableEmoji = true # 是否支持Emoji表情符号 7theme = \u0026#34;jane\u0026#34; # 选用jane主题 8hasCJKLanguage = true # 自动检测是否包含 中文\\日文\\韩文 9paginate = 10 # 首页每页显示的文章数目 10rssLimit = 20 # 限制 Rss 文章输出数量 11disqusShortname = \u0026#34;\u0026#34; # disqus_shortname 12googleAnalytics = \u0026#34;\u0026#34; # 配置google统计 13copyright = \u0026#34;\u0026#34; # 默认为下面配置的author.name， 14 15# 关于语言 16defaultContentLanguage = \u0026#34;zh-cn\u0026#34; # 默认博客语言环境 17[languages.zh-cn] # 语言支持 18 languageCode = \u0026#34;zh-cn\u0026#34; 19 20# 关于语法高亮，具体使用可查看https://gohugo.io/content-management/syntax-highlighting/ 21PygmentsCodeFences = true # Enable syntax highlighting with GitHub flavoured code fences 22PygmentsUseClasses = true # Use CSS classes to format highlighted code 23PygmentsCodefencesGuessSyntax = true # 24PygmentsOptions = \u0026#34;linenos=table\u0026#34; # 开启显示行号 25 26[author] # 作者名称 27 name = \u0026#34;sixdian\u0026#34; 28[sitemap] # 站点地图 29 changefreq = \u0026#34;weekly\u0026#34; 30 priority = 0.5 31 filename = \u0026#34;sitemap.xml\u0026#34; 32#------------------------------------------------------------------- 33 34#菜单设置 35#------------------------------------------------------------------- 36[[menu.main]] 37 name = \u0026#34;主页\u0026#34; 38 weight = 10 39 identifier = \u0026#34;home\u0026#34; 40 url = \u0026#34;/\u0026#34; 41[[menu.main]] 42 name = \u0026#34;归档\u0026#34; 43 weight = 20 44 identifier = \u0026#34;archives\u0026#34; 45 url = \u0026#34;/post/\u0026#34; 46[[menu.main]] 47 name = \u0026#34;分类\u0026#34; 48 weight = 30 49 identifier = \u0026#34;categories\u0026#34; 50 url = \u0026#34;/categories/\u0026#34; 51[[menu.main]] 52 name = \u0026#34;标签\u0026#34; 53 weight = 40 54 identifier = \u0026#34;tags\u0026#34; 55 url = \u0026#34;/tags/\u0026#34; 56[[menu.main]] 57 name = \u0026#34;关于\u0026#34; 58 weight = 50 59 identifier = \u0026#34;about\u0026#34; 60 url = \u0026#34;/about/\u0026#34; 61[[menu.main]] 62 name = \u0026#34;友链\u0026#34; 63 weight = 60 64 identifier = \u0026#34;links\u0026#34; 65 url = \u0026#34;/links/\u0026#34; 66[[menu.main]] 67 name = \u0026#34;订阅\u0026#34; 68 weight = 70 69 identifier = \u0026#34;feed\u0026#34; 70 url = \u0026#34;/index.xml\u0026#34; 71#------------------------------------------------------------------- 72 73#其他参数设置 74#------------------------------------------------------------------- 75[params] 76 since = \u0026#34;2022\u0026#34; # 站点建立时间 77 homeFullContent = false # 主页是否显示全部文章内容 78 rssFullContent = true # if false, Rss feed instead of the summary 79 logotitle: \u0026#34;六点随笔\u0026#34; # 博客标题，默认值是上面设置的title，也就是网址名称 80 keywords = [\u0026#34;Hugo\u0026#34;, \u0026#34;linux\u0026#34;, \u0026#34;emacs\u0026#34;, \u0026#34;CPU\u0026#34;] # 关键字 81 description: \u0026#34;\u0026#34; # 网页描述 82 archive-paginate = 30 # 归档、标签、分类每页显示的文章数目 83 dateFormatToUse = \u0026#34;2006-01-02\u0026#34; # 日期显示格式，查看可支持的格式见https://gohugo.io/functions/format/ 84 moreMeta = true # 是否显示字数统计与阅读时间 85 showMenuLanguageChooser = true # 显示语言选择开关 86 showAuthorInfo = true # 文章末尾显示作者信息 87 88 # 一些全局开关，这些是默认值，也可以在每一篇内容的 front matter 中对单篇内容关闭或开启某些功能，在 archetypes/default.md 查看更多信息。 89 toc = true # 是否开启目录 90 photoswipe = true # 是否启用PhotoSwipe（图片可点击） 91 bootcdn = true # 是否使用bootcdn 92 mathjax = false # 是否使用mathjax（数学公式） 93 contentCopyright = \u0026#39;六点创作，转载请注明出处！\u0026#39; # 版权声明 94 95 customCSS = [] # if [\u0026#39;custom.css\u0026#39;], load \u0026#39;/static/css/custom.css\u0026#39; file 96 customJS = [] # if [\u0026#39;custom.js\u0026#39;], load \u0026#39;/static/js/custom.js\u0026#39; file 97#------------------------------------------------------------------- 98 99# CDN设置 100#------------------------------------------------------------------- 101 [params.publicCDN] # load these files from public cdn 102 enable = true 103 jquery = \u0026#39;\u0026lt;script src=\u0026#34;https://cdn.jsdelivr.net/npm/jquery@3.2.1/dist/jquery.min.js\u0026#34; integrity=\u0026#34;sha256-hwg4gsxgFZhOsEEamdOYGBf13FyQuiTwlAQgxVSNgt4=\u0026#34; crossorigin=\u0026#34;anonymous\u0026#34;\u0026gt;\u0026lt;/script\u0026gt;\u0026#39; 104 slideout = \u0026#39;\u0026lt;script src=\u0026#34;https://cdn.jsdelivr.net/npm/slideout@1.0.1/dist/slideout.min.js\u0026#34; integrity=\u0026#34;sha256-t+zJ/g8/KXIJMjSVQdnibt4dlaDxc9zXr/9oNPeWqdg=\u0026#34; crossorigin=\u0026#34;anonymous\u0026#34;\u0026gt;\u0026lt;/script\u0026gt;\u0026#39; 105 gitmentJS = \u0026#39;\u0026lt;script src=\u0026#34;https://cdn.jsdelivr.net/npm/gitment@0.0.3/dist/gitment.browser.min.js\u0026#34; crossorigin=\u0026#34;anonymous\u0026#34;\u0026gt;\u0026lt;/script\u0026gt;\u0026#39; 106 gitmentCSS = \u0026#39;\u0026lt;link rel=\u0026#34;stylesheet\u0026#34; href=\u0026#34;https://cdn.jsdelivr.net/npm/gitment@0.0.3/style/default.min.css\u0026#34; crossorigin=\u0026#34;anonymous\u0026#34;\u0026gt;\u0026#39; 107 photoswipe = \u0026#39;\u0026lt;script src=\u0026#34;https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.js\u0026#34; integrity=\u0026#34;sha256-AC9ChpELidrhGHX23ZU53vmRdz3FhKaN9E28+BbcWBw=\u0026#34; crossorigin=\u0026#34;anonymous\u0026#34;\u0026gt;\u0026lt;/script\u0026gt;\u0026#39; 108 photoswipeUI = \u0026#39;\u0026lt;script src=\u0026#34;https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js\u0026#34; integrity=\u0026#34;sha256-UKkzOn/w1mBxRmLLGrSeyB4e1xbrp4xylgAWb3M42pU=\u0026#34; crossorigin=\u0026#34;anonymous\u0026#34;\u0026gt;\u0026lt;/script\u0026gt;\u0026#39; 109 photoswipeCSS = \u0026#39;\u0026lt;link rel=\u0026#34;stylesheet\u0026#34; href=\u0026#34;https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.css\u0026#34; integrity=\u0026#34;sha256-SBLU4vv6CA6lHsZ1XyTdhyjJxCjPif/TRkjnsyGAGnE=\u0026#34; crossorigin=\u0026#34;anonymous\u0026#34;\u0026gt;\u0026#39; 110 photoswipeSKIN = \u0026#39;\u0026lt;link rel=\u0026#34;stylesheet\u0026#34; href=\u0026#34;https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.css\u0026#34; integrity=\u0026#34;sha256-c0uckgykQ9v5k+IqViZOZKc47Jn7KQil4/MP3ySA3F8=\u0026#34; crossorigin=\u0026#34;anonymous\u0026#34;\u0026gt;\u0026#39; 111#------------------------------------------------------------------- 112 113# 下面是关于评论系统，更新显示commit内容，谷歌搜索，文章打赏，访问数据统计等等 114#------------------------------------------------------------------- 115 [params.utteranc] # utteranc is a comment system based on GitHub issues. see https://utteranc.es 116 enable = false 117 repo = \u0026#34;xianmin/comments-for-hugo-theme-jane\u0026#34; # The repo to store comments 118 issueTerm = \u0026#34;pathname\u0026#34; 119 120 [params.gitment] # Gitment is a comment system based on GitHub issues. see https://github.com/imsun/gitment 121 owner = \u0026#34;\u0026#34; # Your GitHub ID 122 repo = \u0026#34;\u0026#34; # The repo to store comments 123 clientId = \u0026#34;\u0026#34; # Your client ID 124 clientSecret = \u0026#34;\u0026#34; # Your client secret 125 126 [params.livere] #LiveRe comment. see https://www.livere.com/ 127 uid = \u0026#34;\u0026#34; 128 129 [params.reward] # 文章打赏 130 enable = false 131 wechat = \u0026#34;/path/to/your/wechat-qr-code.png\u0026#34; # 微信二维码 132 alipay = \u0026#34;/path/to/your/alipay-qr-code.png\u0026#34; # 支付宝二维码 133 134 [params.counter.busuanzi] # a Chinese visitor counter # 卜算子计数器 135 enable = false 136 137 [params.counter.leancloud] # Chinese leancloud visitor counter # leancloud 计数器 138 enable = false 139 appId = \u0026#34;\u0026#34; 140 appKey = \u0026#34;\u0026#34; 141 142 [params.commentCount.disqus] # show counts of comments for Disqus 143 enable = false 144 145 [params.search.google] # google custom search, see https://cse.google.com 146 enable = false 147 id = \u0026#34;002186711602136249422:q1gkomof_em\u0026#34; 148 title: \u0026#34;Search\u0026#34; 149 150 [params.gitInfo] 151 gitRepo = \u0026#34;https://github.com/xianmin/xianmin.org\u0026#34; 152 showCommitMessage = false 153#------------------------------------------------------------------- 154 155#社交链接 156#------------------------------------------------------------------- 157# [params.social] 158# a-email = \u0026#34;mailto:your@email.com\u0026#34; 159# b-stack-overflow = \u0026#34;http://localhost:1313\u0026#34; 160# c-twitter = \u0026#34;http://localhost:1313\u0026#34; 161# d-facebook = \u0026#34;http://localhost:1313\u0026#34; 162# e-linkedin = \u0026#34;http://localhost:1313\u0026#34; 163# f-google = \u0026#34;http://localhost:1313\u0026#34; 164# g-github = \u0026#34;http://localhost:1313\u0026#34; 165# h-weibo = \u0026#34;http://localhost:1313\u0026#34; 166# i-zhihu = \u0026#34;http://localhost:1313\u0026#34; 167# j-douban = \u0026#34;http://localhost:1313\u0026#34; 168# k-pocket = \u0026#34;http://localhost:1313\u0026#34; 169# l-tumblr = \u0026#34;http://localhost:1313\u0026#34; 170# m-instagram = \u0026#34;http://localhost:1313\u0026#34; 171# n-gitlab = \u0026#34;http://localhost:1313\u0026#34; 172# o-goodreads = \u0026#34;http://localhost:1313\u0026#34; 173# p-coding = \u0026#34;http://localhost:1313\u0026#34; 174# q-bilibili = \u0026#34;http://localhost:1313\u0026#34; 175# r-codeforces = \u0026#34;http://localhost:1313\u0026#34; 176# s-mastodon = \u0026#34;http://localhost:1313\u0026#34; 177#------------------------------------------------------------------- © 2022-2023 🚴 sixdian\n","permalink":"https://omgkill.github.io/post/blob/jane/","tags":["hugo","blob"],"title":"Hugo 使用 Jane 主题常用的一些配置"},{"categories":["docker"],"contents":" 安装docker\nyum install -y docker 创建网络\ndocker network create test_net 创建redis1\ndocker run -d \u0026ndash;rm \u0026ndash;name redis1 -h redis1 \u0026ndash;net test_net 10.0.3.2:5001/base_redis 创建redis2\ndocker run -d \u0026ndash;rm \u0026ndash;name redis2 -h redis2 \u0026ndash;net test_net 10.0.3.2:5001/base_redis 测试\ndocker exec -it redis1 ping -c 3 redis2 ","permalink":"https://omgkill.github.io/post/docker/docker%E5%8D%95%E6%9C%BA%E5%AE%B9%E5%99%A8%E4%BA%92%E8%BF%9E/","tags":["docker","网络"],"title":"Docker单机容器互连"},{"categories":["JVM"],"contents":"一部分jvm参数详解网址：http://www.51gjie.com/java/551.html 与gc无关设定 -D user.timezone=UTC\n指定时区 测试服启动指定时区 JVM运行时增加参数，指定时区 -Dfile.encoding=UTF-8\n文件格式\n-Djava.util.Arrays.useLegacyMergeSort=true\nArrays.sort方法和Collections.sort（底层也是Arrays.sort）方法被替换了，如果违反了新的排序规则就可能会出现IllegalArgumentException异常（这里是可能，不是一定）。\n之前的方法会忽略掉一种情况，如果想使用之前的方法，这里提供了一个新的参数，java.util.Arrays.useLegacyMergeSort去还原之前的方法。 最容易出错的情况就是自己写的比较器只写了1和-1的情况，而没有写0，\n如： 这样会导至当x == y时，compare(x,y)的结果为 -1，此时sgn(compare(x,y)) = -1，这与第一种满足条件sgn(compare(x, y)) == -sgn(compare(y, x))相违背。所以会抛出IllegalArgumentException异常。 对于 x \u0026gt; y ? 1 : -1 ，当x == y时，也只是可可能会抛出异常，什么会抛出该异常，这要取绝于TimSort算法。\n-XX:HeapDumpPath=${目录}\n参数表示生成DUMP文件的路径，也可以指定文件名称，例如：-XX:HeapDumpPath=${目录}/java_heapdump.hprof。如果不指定文件名，默认为：java__heapDump.hprof。\ngc相关 XX:MaxTenuringThreshold\n生存次数达到进入老年代\nXX:MaxGCPauseMillis \u0026ndash; 每次gc暂停时间\n是所有gc暂停时间吗？？还是young gc、mix gc\n-XX:G1HeapRegionSize.\nregion 大小，应该2的幂方，建议区域数量接近于2048\nWhen setting the region size, it’s important to understand the number of regions your heap-to-size ratio will create because the fewer the regions, the less flexibility G1 has and the longer it takes to scan, mark and collect each of them. In all cases, empty regions are added to an unordered linked list also known as the \u0026ldquo;free list\u0026rdquo;.\nG1ReservePercent\n预留内存\nG1HeapWastePercent\n最小可回收半分比，超过了才进行gc处理\n默认值5%，也就是在全局并发标记结束后能够统计出所有可被回收的垃圾占Heap的比例值，如果超过5%，那么就会触发之后的多轮Mixed GC，mixed gc会同时回收年轻代+老年代，而这个参数可以指定mixed gc触发的时机。而且mixed gc 可以在 gc log中清楚的记录下来。这个参数与InitiatingHeapOccupancyPercent 结合使用的话可以提前回收老年代，让老年代提前释放空间。\n默认5%， gc过程中空出来的region是否充足阈值，在混合回收的时候，对Region回收都是基于复制算法进行的，都是把要回收的Region里的存活对象放入其他 Region，然后这个Region中的垃圾对象全部清理掉，这样的话在回收过程就会不断空出来新的 Region，一旦空闲出来的Region数量达到了堆内存的5%，此时就会立即停止混合回收，意味着 本次混合回收就结束了\nG1MixedGCLiveThresholdPercent-\n一个 区域活对象百分比。低于这个百分比，才能对region回收\n-\u0026gt; 默认85%，region中的存活对象低于这个值时才会回收该region，如果超过这个值，存活对象过多，回收的的意义不大。\n-Xss\n设置单个线程栈大小，比如-Xss512K，数值越小，一个线程栈里能分配的栈帧就越少，说明可以开启的线程数越多\n‐XX:MetaspaceSize\n设置方法区的大小，也是触发GC的阈值，比如\n‐XX:MaxMetaspaceSiz\n设置方法区的最大值，比如‐XX:MaxMetaspaceSize=256M\n-XX:+HeapDumpOnOutOfMemoryError\n参数表示当JVM发生OOM时，自动生成DUMP文件。\n-XX:MaxGCPauseMillis=150\n设置每次年轻代垃圾回收的最长时间，如果无法满足此时间，JVM会自动调整年轻代大小，以满足此值\n-XX:+UseAdaptiveSizePolicy：\n设置此选项后，并行收集器会自动选择年轻代区大小和相应的Survivor区比例，以达到目标系统规定的最低相应时间或者收集频率等，此值建议使用并行收集器时，一直打开。\n-XX:G1NewSizePercent\n设置新生代初始占比，在系统 运行中，JVM会不停的给年轻代增加更多的Region，但是最多新生代的占比不会超过 60%\n可以 通过“-XX:G1MaxNewSizePercent”调整\n年轻代最大占比\n-XX:+UseConcMarkSweepGC:\n代表垃圾回收策略为并发收集器。\nXX:G1MixedGCCountTarget\n在一次回收过程中指定做几次筛选回收(默认8次)，在最后一个筛选回收阶段可以回收一会，然后暂停回收，恢复系统运行，一会再开始回收，这样可以让系统不至于单次停顿时间过长。\n-XX:ConcGCThreads=2\n-XX:InitiatingHeapOccupancyPercent=45\n应该不仅仅是老年代，应该包含年轻代和年老代？？，如果这样，那触发频率应该很高啊。\n老年代占用空间达到整堆内存阈值(默认45%)，则执行 新生代和老年代的混合收集(MixedGC)，比如我们之前说的堆默认有2048个region，如果有接近 1000个region都是老年代的region，则可能就要触发MixedGC了\n-XX:NewSize=n：\n‐Xmn -\u0026gt; 设置年轻代大小，比如‐Xmn2g\n设置年轻代大小\nXX:NewRatio\n设置年轻代和年老代的比值。如:为3，表示年轻代与年老代比值为1：3，年轻代占整个年轻代年老代和的1/4\nXX:SurvivorRatio\n年轻代中Eden区与两个Survivor区的比值。注意Survivor区有两个。如：3，表示Eden：Survivor=3：2，一个Survivor区占整个年轻代的1/5\n-XX:GCTimeRatio=n:\n设置垃圾回收时间占程序运行时间的百分比。公式为1/(1+n)\n‐XX:PretenureSizeThreshold\n可以设置大对象的大小，比如‐XX:PretenureSizeThreshold=100000000 单位为btye。\n‐XX:MaxTenuringThreshold\n设置分代年龄，比如‐XX:MaxTenuringThreshold=10 默认为15。\n‐XX:-HandlePromotionFailure\n老年代分配担保机制参数，1.8默认开启。\n‐XX:-UseAdaptiveSizePolicy\n禁止JVM自动优化eden和Survivor默认比例8：1：1，反之JVM默认有这个参数‐XX:+UseAdaptiveSizePolicy，会导致这个比例自动变化。\n‐XX:SurvivorRatio\n设置Eden和Survivor大小比如 ‐XX:SurvivorRatio =8，注意Survivor区有两个。表示Eden：Survivor=8：2，一个Survivor区占整个年轻代的1/10。\n‐XX:G1HeapRegionSize\n指定分区大小(1MB~32MB，且必须是2的幂)，默认将整堆划分为2048个分区\n‐XX:TargetSurvivorRatio\nSurvivor区的填充容量(默认50%)，Survivor区域里的一批对象(年龄1+年龄2+年龄n的多个年龄对象)总和超过了Survivor区域的50%，此时就会把年龄n(含)以上的对象都放入老年代\n-XX:ParallelGCThreads=4：\n配置并行收集器的线程数，即：同时多少个线程一起进行垃圾回收。此值最好配置与处理器数目相等。\ncode 1 2、对于并行gc收集器： 2 2.1、比如ps的时候： 3 -XX:ParallelGCThreads={value} 这个参数是指定并行 GC 线程的数量，一般最好和 CPU 核心数量相当。默认情况下，当 CPU 数量小于8， ParallelGCThreads 的值等于 CPU 数量，当 CPU 数量大于 8 时，则使用公式：ParallelGCThreads = 8 + ((N - 8) * 5/8) = 3 +（（5*CPU）/ 8）；同时这个参数只要是并行 GC 都可以使用，不只是 ParNew。 4 5 由于GC操作会暂停所有的应用程序线程，JVM为了尽量缩短停顿时间就必须尽可能地利用更多的CPU资源。这意味着，默认情况下，JVM会在机器的每个CPU上运行一个线程，最多同时运行8个。一旦达到这个上限，JVM会调整算法，每超出5/8个CPU启动一个新的线程。所以总的线程数就是（这里的N代表CPU的数目）：ParallelGCThreads = 8 + ((N - 8) * 5/8) 6 有时候使用这个算法估算出来的线程数目会偏大。如果应用程序使用一个较小的堆（譬如大小为1 GB）运行在一个八颗CPU的机器上，使用4个线程或者6个线程处理这个堆可能会更高效。在一个128颗CPU的机器上，启动83个垃圾收集线程可能也太多了，除非系统使用的堆已经达到了最大上限。 7 8 2.2、cms的时候： 9 -XX:ParallelGCThreads 由于是并行处理器，当然也可以指定线程数。 10 默认并发线程数是：（ParallelGCThreads + 3）/ 4） 11 12 13 附带： 14 1、CPU总核数 = 物理CPU个数 * 每颗物理CPU的核数 15 2、总逻辑CPU数 = 物理CPU个数 * 每颗物理CPU的核数 * 超线程数 16 17 3、相关命令： 18 19 3.1、查看CPU信息（型号）[root@AAA ~]# cat /proc/cpuinfo | grep name | cut -f2 -d: | uniq -c 20 21 28 Intel(R) Xeon(R) CPU E5-2650 v2 @ 2.60GHz 22 23 3.2、查看物理CPU个数 [root@AAA ~]# cat /proc/cpuinfo| grep \u0026#34;physical id\u0026#34;| sort| uniq| wc -l 24 25 1 26 27 3.3、查看每个物理CPU中core的个数(即核数) [root@AAA ~]# cat /proc/cpuinfo| grep \u0026#34;cpu cores\u0026#34;| uniq 28 29 cpu cores : 14 30 31 3.4、查看逻辑CPU的个数 [root@AAA ~]# cat /proc/cpuinfo| grep \u0026#34;processor\u0026#34;| wc -l 32 33 12 回收模式相关 -XX:+UseG1GC 使用g1gc\n-XX:+UseSerialGC： 代表垃圾回收策略为串行收集器，即在整个扫描和复制过程采用单线程的方式来进行，适用于单CPU、新生代空间较小及对暂停时间要求不是非常高的应用上，是client级别默认的GC方式，主要在JDK1.5之前的垃圾回收方式。\n-XX:+UseParallelGC： 代表垃圾回收策略为并行收集器(吞吐量优先)，即在整个扫描和复制过程采用多线程的方式来进行，适用于多CPU、对暂停时间要求较短的应用上，是server级别默认采用的GC方式。 此配置仅对年轻代有效。该配置只能让年轻人使用并发收集，而年老代仍旧使用串行收集\n-XX:+UseParallelOldGC： 配置年老代垃圾收集方式为并行收集。JDK6.0支持对年老代并行收集\n日志相关 ‐ XX:+PrintGCDetails\n打印GC日志\n‐ XX:+PrintGCTimeStamps\n打印GC时间\n‐ XX:+PrintGCDateStamps\n打印GC日期\n‐ Xloggc\n将GC日志保存为文件，比如‐Xloggc:./gc.log\n- 使用了参数 1-XX:ConcGCThreads=2 2-XX:+DisableExplicitGC 3-XX:G1MixedGCCountTarget=16 4-XX:G1RSetRegionEntries=1024 5-XX:+G1SummarizeRSetStats 6-XX:G1SummarizeRSetStatsPeriod=1 7-XX:GCTimeRatio=4 8-XX:+HeapDumpOnOutOfMemoryError 9-XX:InitialHeapSize=524288000 10-XX:InitialTenuringThreshold=2 11-XX:InitiatingHeapOccupancyPercent=45 12-XX:MaxGCPauseMillis=150 13-XX:MaxHeapSize=3145728000 14-XX:MaxTenuringThreshold=2 15-XX:-OmitStackTraceInFastThrow 16-XX:ParallelGCThreads=4 17-XX:+PrintCommandLineFlags 18-XX:+PrintFlagsFinal 19-XX:+PrintGC 20-XX:+PrintGCApplicationStoppedTime 21-XX:+PrintGCDateStamps 22-XX:+PrintGCDetails 23-XX:+PrintGCTimeStamps 24-XX:+PrintStringTableStatistics 25-XX:+PrintTenuringDistribution 26-XX:StringTableSize=200003 27-XX:SurvivorRatio=6 28-XX:+UnlockDiagnosticVMOptions 29-XX:+UseCompressedClassPointers 30-XX:+UseCompressedOops 31-XX:+UseG1GC 32-XX:-UseLargePagesIndividualAllocation 33-XX:+UseStringDeduplication ","permalink":"https://omgkill.github.io/post/jvm/jvm-gc%E5%8F%82%E6%95%B0/","tags":["jvm","GC"],"title":"jvm gc参数"},{"categories":["JVM"],"contents":"使用须知 热更是通过arthas redefine来实现的 目前热更支持操作 可以修改方法体 可以添加或删除 private static 或 private (static) final（这个上次测试有问题） 方法 可以删除热更新新加的方法，不可以删除本来的方法 可以添加、删除或修改内部类，但要注意不要改变内部类首次被调用的顺序 热更不支持操作 不能添加、删除、修改类字段、以及字段的访问控制符 热部署不会重新初始化类，所以类成员变量还是之前的值 类的继承关系、接口不能改变，包括添加、删除、修改或改变先后顺序等 不能修改类字段的排列顺序； 不能增加、修改或删除方法签名、访问控制符，可以添加或删除 private static 或 private (static) final 方法 不能改变 lambda 表达式在源码文件中出现的顺序； 不能热部署增加、删除或修改闭包的源码文件； 枚举不能新增或删除 热部署后，不要对热更新的类使用arthas这些 jad/watch/trace/monitor/tt 命令 redefine命令和jad/watch/trace/monitor/tt等命令会冲突 观察到的现象 如果先使用redefine，再使用jad/watch/trace/monitor/tt这些命令，这时redefine 修改的代码还是存在的. 如果使用了jad/watch/trace/monitor/tt命令，再使用redefine 热更新，这时再使用jad/watch/trace/monitor/tt命令，就会导致字节码重置，热更新的代码就丢失了 原因 jad/watch/trace/monitor/tt命令也是用的热部署，不过使用的另一种方式：retransform。但第一次使用retransform 会保留一份字节码，后续再使用retransform会以这份字节码为基础 如果是枚举或者内部类，需要找到对应的class文件热更 测试热部署服脚本 脚本地址：http://svn.super-chameleon.com:8822/svn/AMS_TD/Source/trunk/Server/Tools/Ops/hot_deploy_test.py 脚本使用python脚本写的， 脚本支持svn号、java类全限定类名、class文件绝对路径来热部署 使用脚本说明 使用svn号进行热部署 会更新最新代码，并编译 通过svn log获取java文件，且是修改文件操作 参数-n， 多个svn号以竖杠分割 示例：python hot_deploy_test.py -n 64013 示例：python hot_deploy_test.py -n 64013|64109 支持指定服id，参数 -s。没有该参数，默认对2002服和2003服进行热更新 示例 python hot_deploy_test.py -n 64013 -s 2002 使用java全限定类名 会更新最新代码，并编译 文件通过搜索项目下对应的class文件获得 参数-j， 多个类以竖杠分割 python hot_deploy_test.py -j com.elex.cok.puredb.model.UserRecruitInfo.java python hot_deploy_test.py -j com.elex.cok.puredb.model.UserRecruitInfo.java|com.elex.cok.puredb.model.UserProfile.java 支持指定服id，参数 -s。没有该参数，默认对2002服和2003服进行热更新 示例 python hot_deploy_test.py -j com.elex.cok.puredb.model.UserRecruitInfo.java -s 2002 使用class绝对路径 仅支持对本机热部署 参数-c ， 多个文件以竖杠分割 示例：python hot_deploy_test.py -c /home/ClashOfKingProject/cok-game/build/classes/java/main/com/elex/cok/puredb/model/UserRecruitInfo.class LINUX/MAC 本机热部署 目前本机只支持class绝对路径来部署 下载arthas,解压，里面会有脚本 as.ash 需要修改hot_deploy_test.py变量` arthas_sh_home 修改成 as.ash在本机的目录 示例：arthas_sh_home = \u0026lsquo;/home/elex/as.sh\u0026rsquo; 热部署脚本参考 : 使用class绝对路径 使用示例：python hot_deploy_test.py -c /home/ClashOfKingProject/cok-game/build/classes/java/main/com/elex/cok/puredb/model/UserRecruitInfo.class WINDOWS 本机热部署 目前本机只支持class绝对路径来部署 下载arthas,解压，里面会有jar arthas-boot.jar 需要修改hot_deploy_test.py变量` arthas_jar_home 修改成 arthas-boot.jar在本机的目录 示例：arthas_jar_home = \u0026lsquo;C:/Users/Administrator/Desktop/arthas/arthas-boot.jar\u0026rsquo; 热部署脚本参考 : 使用class绝对路径 使用示例 python hot_deploy_test.py -c \u0026lsquo;C:\\Users\\Administrator\\Desktop\\td\\ClashOfKingProject\\cok-game\\build\\classes\\java\\main\\com\\elex\\cok\\puredb\\model\\UserProfile.class\u0026rsquo; mybatis mapper.xml 热部署 目前不支持，后续补充 线上热部署 脚本地址:http://svn.super-chameleon.com:8822/svn/AMS_TD/Source/trunk/Server/Tools/Deploy/deploy_global_hot_deploy.py 脚本使用python脚本写的，用的fabric 2 线上部署仅支持java全限定类名 部署流程 热部署1服指令 脚本参数p,多个类以竖杠分割 示例fab -f deploy_global_hot_deploy.py df:p=com.elex.cok.puredb.model.UserRecruitInfo.java 脚本进行的处理：更新代码、编译、把class上传1服，执行热部署命令 让QA或策划测试没问题，再进行下面部署 其他服热部署 脚本参数p，多个类以竖杠分割 示例：fab -f deploy_global_hot_deploy.py do:p=com.elex.cok.puredb.model.UserRecruitInfo.java 脚本进行的处理，其他服同步1服hot_deploy文件夹，执行热部署命令 扩展 Java系列 | 远程热部署在美团的落地实践：https://tech.meituan.com/2022/03/17/java-hotswap-sonic.html JVM源码分析之javaagent原理完全解读 ： http://lovestblog.cn/blog/2015/09/14/javaagent/ JVM Attach机制实现：http://lovestblog.cn/blog/2014/06/18/jvm-attach/ Java探针技术-动态重定义Class：https://blog.51cto.com/alex4dream/2740140 ","permalink":"https://omgkill.github.io/post/jvm/%E4%BB%A3%E7%A0%81%E7%83%AD%E6%9B%B4%E8%84%9A%E6%9C%AC%E8%AF%B4%E6%98%8E/","tags":["jvm","hotfix"],"title":"代码热更脚本说明"},{"categories":["redis"],"contents":"redis cluster 迁移 准备 迁移工具，redis shake \u0026ndash; https://github.com/alibaba/RedisShake 生成dump文件 找一个机器，可以访问被迁移redis cluster 的机器 wget https://github.com/alibaba/RedisShake/releases/download/release-v2.1.1-20210903/release-v2.1.1-20210903.tar.gz tar -zxvf release-v2.1.1-20210903.tar.gz cd release-v2.1.1-20210903 修改配置，vi redis-shake.conf 1 #配置source.type, source.address 2 #示例 3 source.type = cluster 4 # 需要配置所有的master 5 source.address = 10.1.xx.xx:6379;10.1.xx.xx:6379;10.1.xx.xx:6379 6 7 # 更多的配置详情，https://github.com/alibaba/RedisShake/wiki/%E7%AC%AC%E4%B8%80%E6%AC%A1%E4%BD%BF%E7%94%A8%EF%BC%8C%E5%A6%82%E4%BD%95%E8%BF%9B%E8%A1%8C%E9%85%8D%E7%BD%AE%EF%BC%9F 执行dump命令 : ./redis-shake.linux -conf=redis-shake.conf -type=dump 文件下多了几个local_dump 文件 恢复数据 一个可以访问目标redis cluster机器 wget https://github.com/alibaba/RedisShake/releases/download/release-v2.1.1-20210903/release-v2.1.1-20210903.tar.gz tar -zxvf release-v2.1.1-20210903.tar.gz cd release-v2.1.1-20210903 把上面导出local_dump文件放到当前目录 修改配置，vi redis-shake.conf 1 #配置source.input.rdb, target.type, target.address 2 #示例 3 source.rdb.input = local_dump.0;local_dump.1;local_dump.2 4 target.type = cluster 5 # 需要配置所有的master 6 target.address = 10.1.xx.xx:6379;10.1.xx.xx:6379;10.1.xx.xx:6379 7 8 # 更多的配置详情，https://github.com/alibaba/RedisShake/wiki/%E7%AC%AC%E4%B8%80%E6%AC%A1%E4%BD%BF%E7%94%A8%EF%BC%8C%E5%A6%82%E4%BD%95%E8%BF%9B%E8%A1%8C%E9%85%8D%E7%BD%AE%EF%BC%9F 执行restore命令 : ./redis-shake.linux -conf=redis-shake.conf -type=restore check 数据是否正确 ps\n迁移后验证同步的正确性的工具 https://github.com/alibaba/RedisFullCheck?spm=a2c6h.12873639.0.0.4b897495FRKWKh 阿里云机器 gcc升级 https://www.alibabacloud.com/help/zh/doc-detail/111881.htm 依次运行以下命令可以安装软件包。 1 # 先安装scl-utils 2 sudo yum install -y scl-utils 3 # 打开YUM仓库支持 4 sudo yum install -y alinux-release-experimentals 5 # 从YUM源安装您需要的软件包，以下示例命令同时安装了SCL插件方式支持的所有开发工具包 6 sudo yum install -y devtoolset-7-gcc devtoolset-7-gdb devtoolset-7-binutils devtoolset-7-make 7 sudo yum install -y devtoolset-8-gcc devtoolset-8-gdb devtoolset-8-binutils devtoolset-8-make 8 sudo yum install -y devtoolset-9-gcc devtoolset-9-gdb devtoolset-9-binutils devtoolset-9-make 安装成功后，您即可使用高版本的GCC以及相关工具。示例代码如下： 1 # 先查看现有的SCL，需要指定库名，本示例代码中，库名为devtoolset-7 2 scl -l devtoolset-7 3 # 运行相关的SCL软件 4 scl enable devtoolset-7 \u0026#39;gcc --version\u0026#39; 部署redis6.0.8集群 https://blog.51cto.com/net881004/2538344 ","permalink":"https://omgkill.github.io/post/redis/redis-cluster-%E8%BF%81%E7%A7%BB/","tags":["redis cluster","redis"],"title":"redis cluster 迁移"},{"categories":["docker","index"],"contents":" 申请端口 check out svn文档，svn地址：http://svn.super-chameleon.com:8822/svn/AMS_TD/Source/trunk/Server/Tools/Ops/ds/port.xlsx 填写自己的名字和端口（端口从10000开始，依次增加，不要重复），提交svn 下载脚本 脚本地址：http://svn.super-chameleon.com:8822/svn/AMS_TD/Source/trunk/Server/Tools/Ops/ds/deploy_docker_game.sh 执行脚本 ./deploy_docker_game.sh -p 端口 -s 服id -n 容器名 端口 端口就是上面申请的端口 服id 这个服id有两个选项，一个是自己的服id，一个是共通使用一个服id 如果是开发，可以使用自己的服id 如果是运营，可以使用共通的服id。共通服id:9000 容器名 这个最好是使用者的名字，以后好区分 一个额外参数 -b，mysql 参数 INNODB_BUFFER_POOL_SIZE， 单位是M,不填默认值是128M 示例：./deploy_docker_game.sh -p 10000 -s 11 -n name -b 6144 脚本执行，会有log显示 看到deploy success说明部署成功 tips docker 目前只支持linux 可以在10.0.3.2服测试/home/ams2/ds 如何操作容器\n通过管理界面操作\nhttp://10.0.3.2:9000/#!/home 或者通过命令行操作容器\n查看当前机器有哪些容器 docker ps 或者 docker container ls 运行容器(这个需要谷歌一下，命令参数比较多) docker run -d 容器名 进入容器 docker exec -it 容器名 bash 退出容器 exit 关闭容器 docker stop 容器名 开启容器 docker start 容器名 但是这个不会启动服务，最好的方式是删除容器，然后使用docker run 删除容器 docker rm 容器名 强制删除 docker rm -f 容器名 查看容器日志 docker logs 容器名 docker logs -f 容器名 容器内ams2部署地址 /home/ams2_deploy 容器内Mysql地址 /home/elex/mysql 容器内Cluster Redis 地址 /home/elex/redis ","permalink":"https://omgkill.github.io/post/docker/%E4%BD%BF%E7%94%A8docker%E5%90%AF%E5%8A%A8%E6%B5%8B%E8%AF%95%E6%9C%8D/","tags":["docker"],"title":"使用docker启动测试服"},{"categories":["jvm"],"contents":"Snapshot-At-The-Beginning 标记方式有两种方式\n增量更新（Increment Update） 初始快照（ Snapshot At The Beginning SATB） SATB（ Snapshot At The Beginning， 初始快照） 是一种将并发标记阶段开始时对象间的引用关系， 以逻辑快照的形式进行保存的手段\n介绍并发标记\n介绍简单标记\n在简单标记中， 所有可从根直接触达的对象都会被添加标记。 带标记的是存活对象， 不带标记的是死亡对象 标记位图\n将用于标记的比特值等信息单独拿出来放到其他地方， 用来匹配对应的对象。\nbottom 表示区域内众多对象的末尾\nnextTAMS 中的 TAMS 是“Top At Marking Start”（标记开始时的 top） 的缩写\nnextTAMS 保存了本次标记开始时的 top， 而 prevTAMS 保存了上次标记开始时的 top。\nnext 是本次标记的标 记位图\nprev 是上次标记的标记位图， 保存了上次标记的结果\n流程\n初始标记阶段\nGC 线程首先会创建标记位图 next nextTAMS 指的 就是标记开始时 top 所在的位置， 所以在这里我们将它和 top 对齐 并发标记阶段\n概念：在并发标记阶段， GC 线程继续扫描在初始标记阶段被标记过的对象， 完成对大部分存活对象的标记\n这个阶段是与用户线程并发执行的，那怎么来标记呢\n首先根据快照，来标记各个引用。\nnew 新对象\n对象成员变量的变化\n记录引用关系，所以需要写屏障技术，称之为 SATB 专用写屏障。\n伪代码\n1 1: def satb_write_barrier(field, newobj): 2 2: if $gc_phase == GC_CONCURRENT_MARK: 3 3: oldobj = *field // (a) 4 4: if oldobj != Null: 5 5: enqueue($current_thread.stab_local_queue, oldobj) // (b) 6 6: 7 7: *field = newobj // (c) 加入队列后的处理\n只扫描未被标记的 已经标记的不处理 并发标记阶段结束后区域的状态\n疑问\n多线程环境下如何加入队列 由GC线程来处理 绑定线程队列 线程本地队列满了，再放入全局队列 并发写一个字段，如果obj3对象field引用了objo, 两个线程并发赋值obj1，obj2. 导致obj1没有加入队列，那obj1会丢失吗 obj1有两种可能，一种是new的，一种是另一个引用。\nobj1 未被 SATB 专用写屏障获知时对象之间的关系\n那obj4移除对obj1的引用会有问题吗\n最终标记阶段\n未装满的 SATB 本地队列 存活对象计数\n这个步骤会扫描各个区域的标记位图 next， 统计区域内存活对象的字节数 收尾工作\nnext_marked_bytes 替换为prev_marked_bytes，同时， prevTAMS 被移到了 nextTAMS 先前的位置 总的流程图 remembered set SATB 队列集合主要用 来记录标记过程中对象之间引用关系的变化 2. 转移专用记忆集合则用 来记录区域之间的引用关系。 通过使用转移专用记忆集合， 在转移时即 使不扫描所有区域内的对象， 也可以查到待转移对象所在区域内的对象 被其他区域引用的情况， 从而简化单个区域的转移处理 3. 那为什么要使用remembered set，什么情况下使用 减少全扫描\n分代垃圾回收，之间是怎么引用的\n分区内部引用 无论是新生代还是老年代的分区内部的引用，都不需要记录引用关系。因为是针对一个分区进行的垃圾回收，要么这个分区被回收，要么不被回收。 年轻代与年轻代之间的引用 G1 的三种回收算法（YGC/MIXED GC/FULL GC）都会全量处理新生代分区，所以新生代都会被遍历到。因此无需记录这种引用关系。 年轻代引用年老代 无需记录。G1 的 YGC 回收新生代，无需这个引用关系。混合 GC 时，G1 会采用新生代分区作为根，那么在遍历新生代分区时就能找到老年代分区了，无需这个引用关系。对于 FGC 来说，所有分区都会被处理，也无需这个引用关系。 年老代引用年轻代 需要记录。YGC 在回收新生代时，如果新生代的对象被老年代引用，那么需要标记为存活对象。即此时的根对象有两种，一个是栈空间 / 全局变量的引用，一个是老年代到新生代的引用。 年老代引用年老代 需要记录。混合 GC 时，只会回收部分老年代，被回收的老年代需要正确的标记哪些对象存活。 记录引用方式\npoint -in point-out 如何记录引用关系\n对象与对象的引用 region 与 region 对象与region region 与 卡表（Card Table） Card Table\n卡表是由元素大小为 1 B 的数组实现的（图 3.3） 。 卡表里的元素称为卡片\n2. 卡表的实体是数组。 数组的元素是 1 B 的卡片， 对应了堆中的 512 B。 脏卡片用灰色表示， 净卡 片用白色表示 3. 根据对象获取对应的卡表 1. 卡表的实体是数组。 数组的元素是 1 B 的卡片， 对应了堆中的 512 B。 2. (对象的地址 － 堆的头部地址)／ 512 4. 因为卡片的大小是 1 B， 所以可以用来表示很多状态。 卡片的种类很多， 我们主要关注以下两种 1. 净卡片 2. 净卡片 记忆集合的构造\n每个区域中都有一个转移专用记忆集合， 它是通过散列表实现的。 散列 表的键是引用本区域的其他区域的地址， 而散列表的值是一个数组， 数 组的元素是引用方的对象所对应的卡片索引。 写屏障\n当对象的域被修改时， 被修改对象所对应的卡片会被转移专用写屏障记 录到转移专用记忆集合中。 转移专用写屏障的伪代码如代码清单\n多线程优化\n记忆集合维护线程\n转移专用记忆集合维护线程主要进行下列处理 从转移专用记忆集合日志的集合中取出转移专用记忆集合日志， 从 头开始扫描 将卡片变为净卡片 检查卡片所对应存储空间内所有对象的域 往域中地址所指向的区域的记忆集合中添加卡片 热卡片\n频繁发生修改的存储空间所对应的卡片称为热卡片（hot card） 热卡 片可能会多次被转移专用记忆集合维护线程处理成脏卡片， 从而加重转 移专用记忆集合维护线程的负担， 因此需要特别处理。 卡片计数表，它记录了卡片变成脏卡片的次 数。 脏卡片阈值（默认是 4） 那GC时，记忆集合如何转移呢\n转移对象 是指参考并发标记提供的信息来选择被转移的区域。 被选中的区域称 为回收集合 2. 是指将回收集合内由根直接引用的对象， 以及被其他区域引用的对象 转移到空闲区域中。 3. 是指以②中转移的对象为起点扫描其子孙对象， 将所有存活对象一并 转移。 当③结束之后， 回收集合内的所有存活对象就转移完成了。 4. 伪代码 ","permalink":"https://omgkill.github.io/post/jvm/%E7%AE%80%E5%8D%95%E4%BB%8B%E7%BB%8D-g1gc-snapshot-at-the-beginning%E4%B8%8Eremembered-sets/","tags":["GC"],"title":"简单介绍 g1gc Snapshot-At-The-Beginning与Remembered Sets"},{"categories":["windows"],"contents":" 在cmd中执行linux命令 wsl linux命令 参考文章：https://docs.microsoft.com/zh-cn/windows/wsl/interop\ncmd进入ubuntu bash\nbash命令利用管道实现，执行命令 run.bat文件\n1@echo off 2echo sh redis.sh | bash redis.sh文件\n1#!/bin/bash 2echo 123456 | sudo -S service redis-server start ","permalink":"https://omgkill.github.io/post/windows/windows%E5%AD%90%E7%B3%BB%E7%BB%9Flinux%E5%91%BD%E4%BB%A4%E4%BD%BF%E7%94%A8/","tags":["windows","linux","wsl"],"title":"windows子系统linux命令使用"},{"categories":["jvm","synchronized"],"contents":"synchronized 关键字 JAVA内存模型\n线程、主内存、工作内存三者交互关系\njava内存模型定义了8中操作\nread（读取）：作用于主内存变量，把一个变量值从主内存传输到线程的工作内存中，以便随后的load动作使用 load（载入）：作用于工作内存的变量，它把read操作从主内存中得到的变量值放入工作内存的变量副本中。 use（使用）：作用于工作内存的变量，把工作内存中的一个变量值传递给执行引擎，每当虚拟机遇到一个需要使用变量的值的字节码指令时将会执行这个操作。 assign（赋值）：作用于工作内存的变量，它把一个从执行引擎接收到的值赋值给工作内存的变量，每当虚拟机遇到一个给变量赋值的字节码指令时执行这个操作。 store（存储）：作用于工作内存的变量，把工作内存中的一个变量的值传送到主内存中，以便随后的write的操作。 write（写入）：作用于主内存的变量，它把store操作从工作内存中一个变量的值传送到主内存的变量中。 lock：作用于主内存的变量，把一个变量标识为一条线程独占的状态 unlock : 作用于主内存变量，它把一个处于锁定状态的变量释放出来，释放后的变量才可以被其他线程锁定 交互图 可知\n有序性 可见性 可预见 syn 重量级锁 状态转换消耗的时间可能比用户代码执行的时间还要长\nsyn锁的过程 执行monitorenter,尝试获取对象锁， 如果对象的锁，如果对象没有被锁定，或者当前对象已经拥有对象的锁，把锁的计数加1\n当没有阻塞\n执行代码 当阻塞\n进行线程上下文切换，jvm和操作系统进行介入（系统调用代价高，需要在用户态和内核态中来回切换） 当前线程挂起，进入阻塞 cpu切换其他线程，加载数据到工作内存 当锁释放，又被唤醒，抢占锁 获取锁，重新加载数据到工作内存，执行， 频繁阻塞，无法使用完整调度时间片 释放锁\n执行monitorexit，锁计数器减1\n锁优化 适应性自旋（Adaptive Spinning）、锁消除（Lock Elimination)、锁粗化（Lock Coarsening）、轻量级（LightWeight Locking） 和偏向锁（Biased Locking）等\n自旋 锁定状态只持续了很短的时间 线程空循环 自适应的自旋锁 锁消除 无用的同步处理 1 User use = new User(); 2 user.addScore(); 锁粗化 1 List\u0026lt;String\u0026gt; stooges = new vector\u0026lt;String\u0026gt;(); 2 stooges.add(\u0026#34;a\u0026#34;); 3 stooges.add(\u0026#34;b\u0026#34;); 4 return stooges.toString(); 对象头的存储\n对象头由两部分信息，对象自身的运行时数据，Mark world; 指向方法区对象类型数据的指针 第一部分用于存储对象自身的运行时数据，如哈希码（HashCode）、GC 分代年龄、锁状态标志、线程持有的锁、偏向线程 ID、偏向时间戳、对象分代年龄，这部分信息称为“Mark Word”；Mark Word 被设计成一个非固定的数据结构以便在极小的空间内存储尽量多的信息，它会根据自己的状态复用自己的存储空间。 第二部分是类型指针，即对象指向它的类元数据的指针，虚拟机通过这个指针来确定这个对象是哪个类的实例； 如果对象是一个 Java 数组，那在对象头中还必须有一块用于记录数组长度的数据。因为虚拟机可以通过普通 Java 对象的元数据信息确定 Java 对象的大小，但是从数组的元数据中无法确定数组的大小。 轻量级锁\n在代码进入同步块的时候，如果同步对象锁状态为偏向状态（就是锁标志位为“01”状态，是否为偏向锁标志位为“1”），虚拟机首先将在当前线程的栈帧中建立一个名为锁记录（Lock Record）的空间，用于存储锁对象目前的Mark Word的拷贝。官方称之为 Displaced Mark Word（所以这里我们认为Lock Record和 Displaced Mark Word其实是同一个概念）。这时候线程堆栈与对象头的状态如图所示 拷贝对象头中的Mark Word复制到锁记录中。 拷贝成功后，虚拟机将使用CAS操作尝试将对象头的Mark Word更新为指向Lock Record的指针，并将Lock record里的owner指针指向对象头的mark word。如果更新成功，则执行步骤（4），否则执行步骤（5）。 如果这个更新动作成功了，那么这个线程就拥有了该对象的锁，并且对象Mark Word的锁标志位设置为“00”，即表示此对象处于轻量级锁定状态，这时候线程堆栈与对象头的状态如下所示： 偏向锁\n检查 mark word 的线程 id 。 如果为空则设置 CAS 替换当前线程 id。如果替换成功则获取锁成功，如果失败则撤销偏向锁。 如果不为空则检查 线程 id为是否为本线程。如果是则获取锁成功，如果失败则撤销偏向锁。 锁状态升级流程 整体流程 syn 地使用\n对象内地多个方法加，synchronized，就会互相阻塞，可以使用同步块 syn锁定的是对象引用， 静态方法加锁 是给class类上锁 非静态方法加锁 是给对象上锁 代码地优化\n缩小锁地范围 减少锁地持有时间 降低所得请求频率 使用带有协调机制的独占锁，使用readWriteLock，这些机制允许更高地并发性 减小锁地粒度 锁分段 使用原子类, AtomicInteger 通常，对象分配操作的开销比同步的开销更低 ps : ","permalink":"https://omgkill.github.io/post/jvm/lock/java%E5%A4%9A%E7%BA%BF%E7%A8%8B%E9%94%81%E7%9A%84%E4%BD%BF%E7%94%A8/","tags":["synchronized"],"title":"java多线程锁的使用"},{"categories":["kindle"],"contents":"kindle 使用技巧分享 kindle的介绍 kindle与ipad的比较 kindle设备管理 kindle推书 kindle词典管理 kindle介绍 kindle是亚马逊一个电子阅读器品牌，目前已经有4个系列。融合亚马逊图书的生态。\nkindle kindle paperwrite kindle voyage kindle Oasis kindle与ipad的比较 kindle优势 墨水屏，护眼 续航时间长 比较小，容易携带，随时阅读 kindle适合的场景小说和漫画,适合户外 kindle全平台覆盖，同步阅读进度 ipad优势 生态丰富 屏幕大 更适合技术类书，对排版要求比较高 kindle设备管理 kindle升级 kindle设备管理 kindle 推书 邮件推书 书的格式 常见书的格式：txt、pdf、epub kindle需要的格式；mobi、azw3 转换的方式 邮件主题 convert 通过软件Calibre 网页转换 kindle词典管理 地址 ：https://www.douban.com/group/topic/31690870/?ref=t\n词典很重要，一个好的词典让你对这个世界多一份理解\n如何装入词典 kindle一些问题的解决方法 刷新慢 耗电 书太多 ","permalink":"https://omgkill.github.io/post/kindle/kindle-%E4%BD%BF%E7%94%A8%E6%8A%80%E5%B7%A7%E5%88%86%E4%BA%AB/","tags":["kindle"],"title":"kindle 使用技巧分享"},{"categories":["code optimize"],"contents":"\u0026ndash; 学习面向对象设计原则\n单一职责\n概念 在面向对象编程领域中，单一功能原则（Single responsibility principle）规定每个类都应该有一个单一的功能，并且该功能应该由这个类完全封装起来。所有它的（这个类的）服务都应该严密的和该功能平行（功能平行，意味着没有依赖）。\n错误例子， 1private static TLServerCommonParam.CommonResponseMessage guildPushMessageLogic(TLGameGuild.GuildPushMessage pushMessage) { 2 int[] index = {0}; 3 switch (pushMessage.getType()) { 4 case GuildApplyType: 5 pushMessage.getUidList().forEach(u -\u0026gt; { 6 TLUserProfile tlUserProfile = GameEngine.getInstance().getTLUserProfile(u); 7 if (tlUserProfile.getUstUser() == null) { 8 index[0]++; 9 return ; 10 } 11 try { 12 USTObject message = new USTObject(); 13 message.buildData(TLGameGuild.LoginGuildG2C.class.getName(), pushMessage.getDetail(index[0]).unpack(TLGameGuild.LoginGuildG2C.class)); 14 PushUtils.pushMessage(tlUserProfile.getUstUser(), PushCMD.PUSH_JOIN_GUILD.getId(), message, true); 15 } catch (Exception e) { 16 LoggerUtil.getInstance().recordException(e); 17 } 18 index[0]++; 19 }); 20 break; 错误原因 这个类是GameGServiceManager，负责game的grpc调用，但这里加了业务逻辑处理，不符合单一职责\n修改 剥离业务逻辑\n1 private static TLServerCommonParam.CommonResponseMessage guildPushMessageLogic(TorchLightGuildServiceInfo.GuildGrpcParamMessage pushMessage) { 2 try { 3 GuildGrpcService.getInstance().handler(pushMessage.getType(), pushMessage); 4 } catch (Exception e) { 5 LoggerUtil.getInstance().recordException(e, String.format(\u0026#34;param = %s\u0026#34;, TLUtils.messageToStr(pushMessage))); 6 } 7 return null; }\n开闭原则\n概念 在面向对象编程领域中，开闭原则规定“软件中的对象（类，模块，函数等等）应该对于扩展是开放的，但是对于修改是封闭的”，这意味着一个实体是允许在不改变它的源代码的前提下变更它的行为。该特性在产品化的环境中是特别有价值的，在这种环境中，改变源代码需要代码审查，单元测试以及诸如此类的用以确保产品使用品质的过程。遵循这种原则的代码在扩展时并不发生改变，因此无需上述的过程。\n错误例子 1 switch (pushMessage.getType()) { 2 case GuildApplyType: 3 ...（业务处理） 4 break; 5 case GuildKickUser: 6 ... 7 break; 8 case GuildModifyRank: 9 ... 10 break; 11 case GuildRedDot: 12 ... 13 break; 14 default: 15 break; 错误原因 每次新增，都要修改方法，不符合开闭原则\n修改 建一个接口，各自实现 服务器启动，类型为key，实现类为value，放到map中。调用时，直接根据类型获取实现类； 做到了对扩展开放，新增需求，只需要新增实现类 1public interface IGuildGrpcHandler { 2 /** 3 * 实现方法 4 */ 5 void handle(TorchLightGuildServiceInfo.GuildGrpcParamMessage paramMessage) throws Exception; 6} 里氏代换原则\n概念 在面向对象的程序设计中，里氏替换原则（Liskov Substitution principle）是对子类型的特别定义。它由芭芭拉·利斯科夫（Barbara Liskov）在1987年在一次会议上名为“数据的抽象与层次”的演说中首先提出。 里氏替换原则的内容可以描述为： “派生类（子类）对象可以在程序中代替其基类（超类）对象。”\n实现例子 GM系统修改数据，例如，修改玩家，修改公会数据。而玩家数据在game模块，公会数据在guild模块。一个最底层的接口，两个模块实现各自的抽象共通类\n依赖倒置原则\n概念 在面向对象编程领域中，依赖反转原则（Dependency inversion principle，DIP）是指一种特定的解耦（传统的依赖关系创建在高层次上，而具体的策略设置则应用在低层次的模块上）形式，使得高层次的模块不依赖于低层次的模块的实现细节，依赖关系被颠倒（反转），从而使得低层次模块依赖于高层次模块的需求抽象。\n错误例子 参考开闭原则错误例子 接口隔离原则\n概念 接口隔离原则（英语：interface-segregation principles， 缩写：ISP）指明客户（client）不应被迫使用对其而言无用的方法或功能。接口隔离原则(ISP)拆分非常庞大臃肿的接口成为更小的和更具体的接口，这样客户将会只需要知道他们感兴趣的方法。这种缩小的接口也被称为角色接口（role interfaces）。接口隔离原则(ISP)的目的是系统解开耦合，从而容易重构，更改和重新部署\n错误例子 1 public interface IUserRank\u0026lt;I extends IScoreProvider\u0026gt; { 2 /** 3 * 获取玩家排行榜 4 * @param uid 玩家uid 5 * @param categoryEnum 分组类型 6 * @return TLRankParam.RankDataG2C 返回排行榜数据 7 */ 8 TLRankParam.RankDataG2C getUserRankG2C(long uid, ConfigEnum.EnumRankCategory categoryEnum, int logicId); 9 /** 10 * 加玩家积分 11 * @param inParam 12 */ 13 List\u0026lt;Double\u0026gt; addUserScore(AbstractRankParam\u0026lt;I\u0026gt; inParam); 14 /** 15 * 公会排行榜奖励 16 */ 17 void rewardGuildRank(); 18 } 错误原因 排行榜功能接口，包含获取排行榜和发奖接口，而有的排行榜没有发奖\n修改 删除排行榜发奖接口方法，增加排行榜发奖接口类\n1 public interface IUserRankReward { 2 /** 3 * 公会排行榜奖励 4 */ 5 void rewardGuildRank(); 6 } 迪米特法则\n概念 每个单元对于其他的单元只能拥有有限的知识：只是与当前单元紧密联系的单元； 每个单元只能和它的朋友交谈：不能和陌生单元交谈； 只和自己直接的朋友交谈。 错误例子 获取配置数据，先从parser获取map，然后再根据id，获取value\n修改 应该传入id，从parser直接获取value\n合成/复合原则\n概念 尽量采用组合(contains-a)、聚合(has-a)的方式而不是继承(is-a)的关系来达到软件的复用目的\n优势 减少代码耦合，增加代码灵活度\n","permalink":"https://omgkill.github.io/post/codeoptimize/%E5%AD%A6%E4%B9%A0%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%E8%AE%BE%E8%AE%A1%E5%8E%9F%E5%88%99/","tags":["code style"],"title":"学习面向对象设计原则"},{"categories":["game"],"contents":"服务器活动排行榜 火鸡活动 , 单服排名 + 单服活动 使用了框架 存储方式 数据库存储，map缓存 排行榜 通过map缓存获取。 通过stream sort Comparator.comparingLong 排序。 相同积分，根据积分时间比较 排期入库 服务启动或刷新配置，只要有新的排期，就会入库。并起线程等待 排期修改 修改排期，不能删掉原排期。应该把当前排期设置过期，然后加新排期 排期 尽量使用排期框架 单人活动 单服排名 + 全活动服 存储方式 数据库存储，map和list 缓存 积分 阶段积分，map存储。实现Comparable接口。 总积分，list存储。实现Comparable接口。 排行榜 阶段积分，通过stream.sorted排序。 总积分，每次加积分，Collections.sort排序。 历史排行榜 每次活动结束，放入数据库 跨服加积分 通过rmi调用 问题 玩家重复出现在排行榜\n1 private static SortedSet\u0026lt;UserScore\u0026gt; scoreRankSet = Collections.synchronizedSortedSet(new TreeSet\u0026lt;\u0026gt;());//阶段积分排名 2 List\u0026lt;UserScore\u0026gt; list = new ArrayList\u0026lt;\u0026gt;(); 3 4\tUserScore userScore = new UserScore(); 5\tuserScore.setUid(\u0026#34;111111111\u0026#34;); 6\tuserScore.setScore(1L); 7\t8\tUserScore userScore1 = new UserScore(); 9\tuserScore1.setUid(\u0026#34;222222222\u0026#34;); 10\tuserScore1.setScore(2L); 11 // 放入list 12\tlist.add(userScore); 13\tlist.add(userScore1); 14 15 // 放入map 16\tMap\u0026lt;String, UserScore\u0026gt; map = new HashMap\u0026lt;\u0026gt;(); 17\tfor (UserScore score:list) { 18\tmap.put(score.getUid(), score); 19\t} 20\t21\tfor (int i = 0; i\u0026lt; list.size(); i++) { 22\tscoreRankSet.add(list.get(i)); 23\t} 24\t25\tUserScore myScore = map.get(\u0026#34;111111111\u0026#34;); 26\tmyScore.setScore(33L); 27\tscoreRankSet.add(myScore); 28\tSystem.out.println(scoreRankSet.size()); TreeSet add方法,使用了treeMap的put方法 1 public V put(K key, V value) { 2 Entry\u0026lt;K,V\u0026gt; t = root; 3 if (t == null) { 4 compare(key, key); // type (and possibly null) check 5 6 root = new Entry\u0026lt;\u0026gt;(key, value, null); 7 size = 1; 8 modCount++; 9 return null; 10 } 11 int cmp; 12 Entry\u0026lt;K,V\u0026gt; parent; 13 // split comparator and comparable paths 14 Comparator\u0026lt;? super K\u0026gt; cpr = comparator; 15 if (cpr != null) { 16 do { 17 parent = t; 18 cmp = cpr.compare(key, t.key); 19 if (cmp \u0026lt; 0) 20 t = t.left; 21 else if (cmp \u0026gt; 0) 22 t = t.right; 23 else 24 return t.setValue(value); 25 } while (t != null); 26 } 27 else { 28 if (key == null) 29 throw new NullPointerException(); 30 @SuppressWarnings(\u0026#34;unchecked\u0026#34;) 31 Comparable\u0026lt;? super K\u0026gt; k = (Comparable\u0026lt;? super K\u0026gt;) key; 32 do { 33 parent = t; 34 cmp = k.compareTo(t.key); 35 if (cmp \u0026lt; 0) 36 t = t.left; 37 else if (cmp \u0026gt; 0) 38 t = t.right; 39 else 40 return t.setValue(value); 41 } while (t != null); 42 } 43 Entry\u0026lt;K,V\u0026gt; e = new Entry\u0026lt;\u0026gt;(key, value, parent); 44 if (cmp \u0026lt; 0) 45 parent.left = e; 46 else 47 parent.right = e; 48 fixAfterInsertion(e); 49 size++; 50 modCount++; 51 return null; 52 } comparable 实现 1 @Override 2 public int compareTo(UserScore o) { 3 return o.getScore().compareTo(getScore()); 4 } 战场秘宝 单服排名 + 全服活动（包含竞技场） 使用框架\n存储方式\n数据库存储，redis 缓存 加积分\n数据表跨服携带 数据表与redis同时存储，并进行同步 redis操作\n加积分，使用redis zIncrby(String key, String uid, long addScore) 获取排行榜，redis zRevrangeByScoreWithScores(String key, long max, long min, int offset, int count) redis key 最好是 key + scheduleId, 然后一周后清除数据\n采集资源排行榜 排行榜 存储方式 数据库，redis 积分 每小时查询sql，存入redis 玩家个人积分，当redis没有，从sql查询，再放入redis redis操作 放入到有序列表，redis rPush(String key, String\u0026hellip; value) 获取排行榜，redis getRangeList(String key, int start, int end) 存入玩家个人信息，hSet(String key, String field, String value) 获取玩家个人信息，hGet(String key, String field) 排行榜 单服排名，排除跨服玩家 存入数据，是排行榜的两倍 玩家信息查询数据库，联盟信息通过缓存获取 圣诞boss 全服排名 + 单服活动 使用框架 存储方式 数据库表、map缓存、 单服redis、全服redis 积分同步 线程循环，查询数据库，放入全服redis，再把全服数据下拉到本地redis redis 操作 加入玩家积分：redis zAdd(String key, String member, long score) 获取排行榜：redis zRevrangeByScoreWithScores(String key, long max, long min, int offset, int count) 活动结束发奖 积分再次同步，然后判断是否全服都已提交，没有，通过线程不断循环。直至全服都已提交数据。获取全服排名，发奖 排行榜 玩家信息通过shareInfo 联盟信息redis GLOBAL_ALLIANCE_INFO 全服redis key与单服redis key 最好有区别 军事要塞 全服排名 + 竞技场 存储方式 redis redis操作 获取玩家 zScore(String key, String member) 加积分redis zIncrby(String key, String member, long score) 获取排行榜redis zRevrangeByScoreWithScores(String key, long max, long min, int offset, int count) 母服获取排行榜 redis getOtherRedis(crossServerId) 排行榜 玩家信息：shareInfo 联盟信息，加联盟积分时，从缓存获取联盟信息，然后放入redis。 加积分是同步 世界boss 全服排名 + 活动服 数据存储 数据库、map缓存 积分同步 查询数据库，放入全服redis，再把全服数据下拉到本地redis redis操作 删除 zRem(String key, String member) 新加 zAdd(String key, String member, long score) 获取排行榜 zRangByDesc(String key, long start, long end) 跨服加积分 rmi 战争游戏 全服排名 + 全服 使用全服框架\n排行榜根据时间排序\n设置加积分时间 实现Comparable接口，先比较积分，再比较积分时间 开启竞技场活动 服务器初始化\n1GameEngine 2 3private void initGameData() { 4 long start = System.currentTimeMillis(); 5 bootUpWorld(); 6 logger.info(\u0026#34;[server init] bootUpWorld, {}ms\u0026#34;, System.currentTimeMillis() - start); 7 8 // 设置服务器状态 9 serverOpenStatus = isServerOpen(); 10 11 // 服务器启动先初始化积分活动相关数据，防止已完成事件积分加不上 12 if (!GameEngine.isActivityServer()) { 13 start = System.currentTimeMillis(); 14 ScoreManager.getInstance().init(); 15 logger.info(\u0026#34;[server init] ScoreManager.getInstance().init, {}ms\u0026#34;, System.currentTimeMillis() - start); 活动框架\n1 protected boolean open() { 2 return !GameEngine.isActivityServer(); 3 } 排行榜\n1 public void refreshRanking(){ 2 3 try{ 4 // 全服都开 5 MilitaryCompetitionManger.getInstance().refresh(); 6 if (GameEngine.isActivityServer()) { 7 return; 8 } 9 LoggerUtil.getInstance().logBySFS(\u0026#34;--------starting refreshing ranking---------\u0026#34;); 10 LevelRankingService.getInstance().refresh();//优先更新用户等级排行榜，找出被封禁的玩家 11 for(IRankingService service: services){ 12 if (service == LevelRankingService.getInstance()) { 13 continue; 14 } 15 service.refresh(); 16 } 合服\n历史排名丢弃 玩家排名携带 联盟积分随盟主携带 王国活动 全服排名 + 分组排行榜 存储方式 数据库表，map缓存，redis 积分同步 查询数据库，放入全服redis，再把全服数据下拉到本地redis redis操作 redis key是 key + groupId 删除 zRem(String key, String member) 新加 zAdd(String key, String member, long score) 获取排行榜 zRangByDesc(String key, long start, long end) 发奖 起线程，等全部上报完后，再发奖 加积分是同步 全服redis key 要与单服有区别 跨服加积分 rmi ","permalink":"https://omgkill.github.io/post/game/%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%B4%BB%E5%8A%A8%E6%8E%92%E8%A1%8C%E6%A6%9C/","tags":["game","record","rank"],"title":"服务器活动排行榜"},{"categories":["hash"],"contents":"简单介绍hash 1、hash是什么 2、hash与equal的关系 相等的对象必须具有相等的hash值 hash值相等不一定相等 3、如何算hash Boolean 1 hash = （value? 1 : 0） byte、char、short、int 1 hash = int ( value ) long 1 hash = (int)( value ^ ( value \u0026gt;\u0026gt;\u0026gt; 32) ) float 1 hash = Float.floatToIntBits( value ) double 1 long = Double.doubleToLongBits( value ) \u0026lt;br/\u0026gt; 2 hash = (int)( long ^ (long \u0026gt;\u0026gt;\u0026gt; 32) ) String 1int h = hash; 2if (h == 0 \u0026amp;\u0026amp; value.length \u0026gt; 0) { 3 char val[] = value; 4 5 for (int i = 0; i \u0026lt; value.length; i++) { 6 h = 31 * h + val[i]; 7 } 8 hash = h; 9} 对象 1public class User{ 2 private int age; 3 private String name; 4 public int hashCode() { 5 int result = 17; 6 result = 31 * result + age; 7 result = 31 * result + name.hashCode(); 8 return result; 9 } 10} 数组 可以一个一个算，也可以直接调用Arrays.hashCode()\n问题： 为什么要用 31 这个数 使用素数减少信息丢失 用移位和减法代替乘法，性能会更好 。例子： 131 * i == (i \u0026lt;\u0026lt; 5) - i; 4、hash冲突 jdk1.8 hashMap 1 static final int hash(Object key) { 2 int h; 3 return (key == null) ? 0 : (h = key.hashCode()) ^ (h \u0026gt;\u0026gt;\u0026gt; 16); 4 } jdk1.7 hashMap 1 final int hash(Object k) { 2 int h = hashSeed; 3 if (0 != h \u0026amp;\u0026amp; k instanceof String) { 4 return sun.misc.Hashing.stringHash32((String) k); 5 } 6 7 h ^= k.hashCode(); 8 9 // This function ensures that hashCodes that differ only by 10 // constant multiples at each bit position have a bounded 11 // number of collisions (approximately 8 at default load factor). 12 h ^= (h \u0026gt;\u0026gt;\u0026gt; 20) ^ (h \u0026gt;\u0026gt;\u0026gt; 12); 13 return h ^ (h \u0026gt;\u0026gt;\u0026gt; 7) ^ (h \u0026gt;\u0026gt;\u0026gt; 4); 14 } 15 16 public static int murmur3_32(int var0, char[] var1, int var2, int var3) { 17 int var4 = var0; 18 int var5 = var2; 19 20 int var6; 21 int var7; 22 for(var6 = var3; var6 \u0026gt;= 2; var4 = var4 * 5 + -430675100) { 23 var7 = var1[var5++] \u0026amp; \u0026#39;\\uffff\u0026#39; | var1[var5++] \u0026lt;\u0026lt; 16; 24 var6 -= 2; 25 var7 *= -862048943; 26 var7 = Integer.rotateLeft(var7, 15); 27 var7 *= 461845907; 28 var4 ^= var7; 29 var4 = Integer.rotateLeft(var4, 13); 30 } 31 32 if (var6 \u0026gt; 0) { 33 char var8 = var1[var5]; 34 var7 = var8 * -862048943; 35 var7 = Integer.rotateLeft(var7, 15); 36 var7 *= 461845907; 37 var4 ^= var7; 38 } 39 40 var4 ^= var3 * 2; 41 var4 ^= var4 \u0026gt;\u0026gt;\u0026gt; 16; 42 var4 *= -2048144789; 43 var4 ^= var4 \u0026gt;\u0026gt;\u0026gt; 13; 44 var4 *= -1028477387; 45 var4 ^= var4 \u0026gt;\u0026gt;\u0026gt; 16; 46 return var4; 47 } 5、链地址法 优势：处理hash冲突比较简单、 链表是动态的，大小不固定、节省空间、增删的操作比较简单、 劣势： 当冲突比较多的时候，慢，另一个是指针需要额外空间 6、redis hash 算法\u0026ndash; MurmurHash2 是一种非加密hash算法，适用于基于hash查找的场景 能给出一个很好的随机分布性 rehash rehash 渐进rehash ","permalink":"https://omgkill.github.io/post/hash/%E7%AE%80%E5%8D%95%E4%BB%8B%E7%BB%8Dhash/","tags":["hash"],"title":"简单介绍hash"},{"categories":["game"],"contents":"这是一次艰难的经历，开始都很简单，但后续却发生很多问题 功能介绍\n要搜索拥有某一种资源最多的玩家，然后发邮件告知目标玩家的名称和坐标 条件有，大本等级、战力、是否是同一个联盟、资源种类、不能有保护罩、不能跨服、不能集团隐藏效果(gameEffect) (这三个就很艰难了)。 过程\n一开始，是使用道具，而且每天重置次数。建了数据库表 然后就是sql了，刚开始，我是用各种left join，然后执行比较慢。当时不以为然，觉得复杂的sql就应该这么长时间。 后来果然被骂了，太烂。重新写。而且执行时间要在一秒内。 要求直接主键关联，发现确实快了许多。 要使用主键，减少其他参数。 不要关联大表，比如worldPoint, 表确实太大了，而且很慢。就算是主键也不行。 发现 \u0026gt; 、 \u0026lt;\u0026gt; 、 is null 并没有很影响速度 到最后发现，最慢的还是 排序 最好精简关联的表，当然能快速筛选出有效数据表，还是要关联的。 难点\n只查询一个玩家，还要判断这个不能是自己。这个怎么做\n不可能在加一个不等于判断，影响速度，可以查出两个玩家，再逻辑判断就可以了 玩家主城，有buff效果，可以隐藏。而且这个效果和大地图是分隔的。如何查。\n这个确实很麻烦，怎么查。当时解决方法有两个，一个是连表查，然后查询出没有该效果的点。但这个表数据是模糊的，在这个表的点不一定有这个效果，会筛出一部分有效玩家。 另一个是先查出20个玩家，再一个一个判断，玩家是否有这个效果。刚好有这个效果的玩家并不是很多，还可以承受。后来就选了后一个方案。 玩家主城点可能被清除，需要判断。数据里可能有无效数据，需要排除。\n这个最初是没有好的方法的，因为连worldPoint表，太大了。无法做。 后来worldPoint表做缓存了，都放入map里了。这个时候可以参考2方法，用逻辑来处理。更快一点 总结\n要有冗余，这样好筛选一点。 缓存要学会利用，sql + 缓存是一种很好的方式 不要返回错误的结果，宁愿抛异常，也不要给玩家一个有错的数据。浪费玩家金钱和时间。玩家对这个功能也就慢慢放弃了 ","permalink":"https://omgkill.github.io/post/game/%E4%B8%80%E4%B8%AA%E6%9F%A5%E8%AF%A2%E6%8B%A5%E6%9C%89%E8%B5%84%E6%BA%90%E6%9C%80%E5%A4%9A%E7%8E%A9%E5%AE%B6/","tags":["game","record"],"title":"一个查询拥有资源最多玩家"},{"categories":["system"],"contents":"操作系统面试题 为解决\n• 计算机系统存储体系\ncpu寄存器、高速缓存、内存、硬盘\n• 程序运行时的内存结构\n程序代码、堆、栈\n• 计算机文件系统，页表结构\n一个文件由目录项、inode和数据块组成。\n1 **1. 目录项：包括文件名和inode节点号。 2 3 2. Inode：又称文件索引节点，包含文件的基础信息以及数据块的指针。 4 5 3. 数据块：包含文件的具体内容。** 页表主要用于计算机内存的虚拟化，每个进程都是一个虚拟的内存地址。然后通过页表去映射到对应内存上。\n• 正数和负数及其浮点数是如何在计算机中表示的?\n正数使用原码\n负数使用补码\n浮点数是一个整数乘以2的整数次幂得到。\n对于float是1位正负，8位指数，其他位是尾数\n谈谈你对线程的认识？\n线程的结构有线程上下文、执行栈、局部变量。\n线程依赖进程获取进程获取资源\n线程相当于进程内的一个独立操作的程序计数器 线程创建销毁比进程少 如果是进程的线程切换也很小 同进程的线程更易于通信 如果默认每个线程使用1mb堆栈空间，则32位地址空间，哪么理论上最大可以开多少组线程？\n3000个线程\n*解释一下什么是操作系统*\n可以管理和运行硬件，硬件可以通过驱动扩展 给软件提供了一个平台。软件无需关心硬件处理，更容易去使用硬件的功能 更有效地使用资源。比如内存和cpu资源，需要一种有效的方式去管理 计算机包含什么\n处理器、存储设备和输入输出部件组成 cpu、寄存器、内存、磁盘、系统总线、gpu、主板、键盘、鼠标、电源 *进程和线程的区别？*\n进程\n进程有资源所有权，包括内存，io设备，io通道，文件 进程是操作系统调度 进程是处理器执行的实体 线程\n为什么要有线程呢：比如说，我有多个逻辑想要并发处理，那我创建多个进程，这里就有几个问题： 进程的创建和停止比较耗时 一个是进程的切换耗费资源， 另一个是多个进程如果共享一个资源还要进程间加锁处理。 进程间的通信也比较耗时 进程间是如何通信的 线程是在进程里创建的，只包含处理逻辑，共享整个进程的资源 线程比进程创建时间少许多 终止线程比进程花费时间少 线程切换比进程切换时间少 线程提高了不同的执行程序间通信的效率 进程之间如何通信 举例说明：文件服务器。当每个新文件请求到达是，会创建新的线程，结束后要销毁。一个进程的多线程可以在多个处理器执行。线程共享数据，线程间传递消息比进程更快\nlinux 多核如何调度一个进程里的多个线程\n线程分类\n内核线程\n有关线程管理的所有工作都是内核完成的，包括创建、撤销和切换都是内核实现的\n用户线程\n由用户程序来管理线程的，通过线程库来创建和销魂线程，内核意识不到线程的存在\n线程库是什么\n线程库事用于用户级线程管理的一个例程包，它包含用于创建和销毁线程的代码、在线程间传递消息和数据的代码、调度线程执行的代码，以及保护和恢复线程上下文的代码\n内核线程与用户线程的优缺点\n用户线程比内核线程优点 由于所有线程管理的数据结构都在一个进程的用户空间地址中，线程切换不需要内核态特权，因此，进程不需要为了线程管理而切换到内核态，这节省了两次状态转换（从用户态到内核态；从内核态返回到用户态）的开销 调度可以是应用程序相关的。可以根据应用的业务自己调度线程 用户级线程可以在任何操作系统运行，不需要对底层内核进行修改以支持用户级线程。线程库是一组供所有应用程序共享的应用程序级别的函数 用户线程比内核线程缺点 在典型的操作系统中，许多系统调用都会引起阻塞。一个线程调用，导致整个进程的线程都阻塞 在纯粹的用户级线程策略中，一个多线程应用程序不能利用多处理器 线程的状态\n就绪、运行、结束、阻塞 进程的状态\n新建、就绪、运行、推出、挂起、阻塞、就绪/挂起、阻塞/挂起\n线程拥有什么\n线程执行状态（运行，就绪） 在未运行时保存的线程上下文；从某种意义上看，线程可被视为进程内的一个独立操作的程序计数器 一个执行栈 用于每个线程局部变量的静态存储空间 与进程内的其他线程共享的对进程的内存和资源访问 *协程与线程的区别*\n协程 协程就是可以由程序自行控制挂起（暂停执行）、恢复（继续在原来暂停的地方执行）的程序 他可以用来实现多任务的协作执行 协程是在线程里创建的，所以协程是串行处理的。 协程创建和暂停的消耗低 *并发和并行有什么区别*\n并行是多个任务在多个处理器执行。 并发是多个任务同时执行，可能是多个处理器，也可能是单个处理器，然后分片执行\n*进程与线程的切换流程？*\n进程切换：\n进入内核态\n1）保存处理器上下文环境，包括程序计数器和其他寄存器。 2）更新当前处于运行态进程的进程控制块，包括将进程的状态改变到另一状态（就绪态、阻塞态、就绪挂起态或退出态）还必须更新其他相关域，包括离开运行态的原因和记账信息。 3）将进程的进程控制块移到相应的队列（就绪、在事件i处阻塞、就绪挂起）。 4）选择另一个进程执行，这方面的内容将在本书的第四部分探讨。 5）更新所选择进程的进程控制块，包括将进程的状态变为运行态。 6）更新内存管理的数据结构，这取决于如何管理地址转换，这方面的内容将在第三部分探讨。 7）恢复处理器在被选择的进程最近一次切换出运行状态时的上下文环境，这可以通过载人程序计数器和其他寄存器以前的值来实现，\n进入用户态\n对于linux来说，线程和进程的最大区别就在于地址空间，对于线程切换，第1步是不需要做的，第2步是进程和线程切换都要做的。\n因为每个进程都有自己的虚拟地址空间，而线程是共享所在进程的虚拟地址空间的，因此同一个进程中的线程进行线程切换时不涉及虚拟地址空间的转换。\n进程切换原因\n中断（时钟中断），陷阱（运行异常），系统调用（内存失效）\n*为什么虚拟地址空间切换会比较耗时？*\n别人说的：\n进程都有自己的虚拟地址空间，把虚拟地址转换为物理地址需要查找页表，页表查找是一个很慢的过程，因此通常使用Cache来缓存常用的地址映射，这样可以加速页表查找，这个Cache就是TLB（translation Lookaside Buffer，TLB本质上就是一个Cache，是用来加速页表查找的）。\n由于每个进程都有自己的虚拟地址空间，那么显然每个进程都有自己的页表，那么当进程切换后页表也要进行切换，页表切换后TLB就失效了，Cache失效导致命中率降低，那么虚拟地址转换为物理地址就会变慢，表现出来的就是程序运行会变慢，而线程切换则不会导致TLB失效，因为线程无需切换地址空间，因此我们通常说线程切换要比较进程切换块，原因就在这里。\n自己想的：\n我们读取一个地址，实际需要访问两次内存。一次是根据页号找到页表数据，一次根据物理地址读取数据。这个是非常耗时的。所以我们希望有一个缓存来保存逻辑地址与物理的地址的映射，这个就实TLB。保存在寄存器了。如果我们切换进程了，那这个就失效了，就导致需要重新缓存。\n*进程间通信方式有哪些？*\n管道/管程：管道这种通讯方式有两种限制，一是半双工的通信，数据只能单向流动，二是只能在具有亲缘关系的进程间使用。进程的亲缘关系通常是指父子进程关系。\n管道可以分为两类：匿名管道和命名管道。匿名管道是单向的，只能在有亲缘关系的进程间通信；命名管道以磁盘文件的方式存在，可以实现本机任意两个进程通信。\n信号 ： 信号是一种比较复杂的通信方式，信号可以在任何时候发给某一进程，而无需知道该进程的状态。\nLinux系统中常用信号：（1）SIGHUP：用户从终端注销，所有已启动进程都将收到该进程。系统缺省状态下对该信号的处理是终止进程。\n（2）SIGINT：程序终止信号。程序运行过程中，按Ctrl+C键将产生该信号。\n（3）SIGQUIT：程序退出信号。程序运行过程中，按Ctrl+\\\\\\\\键将产生该信号。\n（4）SIGBUS和SIGSEGV：进程访问非法地址。\n（5）SIGFPE：运算中出现致命错误，如除零操作、数据溢出等。\n（6）SIGKILL：用户终止进程执行信号。shell下执行kill -9发送该信号。\n（7）SIGTERM：结束进程信号。shell下执行kill 进程pid发送该信号。\n（8）SIGALRM：定时器信号。\n（9）SIGCLD：子进程退出信号。如果其父进程没有忽略该信号也没有处理该信号，则子进程退出后将形成僵尸进程。\n信号量：信号量是一个计数器，可以用来控制多个进程对共享资源的访问。它常作为一种锁机制，防止某进程正在访问共享资源时，其他进程也访问该资源。因此，主要作为进程间以及同一进程内不同线程之间的同步手段。\n消息队列：消息队列是消息的链接表，包括Posix消息队列和System V消息队列。有足够权限的进程可以向队列中添加消息，被赋予读权限的进程则可以读走队列中的消息。消息队列克服了信号承载信息量少，管道只能承载无格式字节流以及缓冲区大小受限等缺点。\n共享内存：共享内存就是映射一段能被其他进程所访问的内存，这段共享内存由一个进程创建，但多个进程都可以访问。共享内存是最快的 IPC 方式，它是针对其他进程间通信方式运行效率低而专门设计的。它往往与其他通信机制，如信号量，配合使用，来实现进程间的同步和通信。\nSocket：与其他通信机制不同的是，它可用于不同机器间的进程通信。\n优缺点：\n管道：速度慢，容量有限； Socket：任何进程间都能通讯，但速度慢； 消息队列：容量受到系统限制，且要注意第一次读的时候，要考虑上一次没有读完数据的问题； 信号量：不能传递复杂消息，只能用来同步； 共享内存区：能够很容易控制容量，速度快，但要保持同步，比如一个进程在写的时候，另一个进程要注意读写的问题，相当于线程中的线程安全，当然，共享内存区同样可以用作线程间通讯，不过没这个必要，线程间本来就已经共享了同一进程内的一块内存。 *进程间同步的方式有哪些？*\n1、临界区：通过对多线程的串行化来访问公共资源或一段代码，速度快，适合控制数据访问。\n优点：保证在某一时刻只有一个线程能访问数据的简便办法。\n缺点：虽然临界区同步速度很快，但却只能用来同步本进程内的线程，而不可用来同步多个进程中的线程。\n2、互斥量：为协调共同对一个共享资源的单独访问而设计的。互斥量跟临界区很相似，比临界区复杂，互斥对象只有一个，只有拥有互斥对象的线程才具有访问资源的权限。\n优点：使用互斥不仅仅能够在同一应用程序不同线程中实现资源的安全共享，而且可以在不同应用程序的线程之间实现对资源的安全共享。\n缺点：\n互斥量是可以命名的，也就是说它可以跨越进程使用，所以创建互斥量需要的资源更多，所以如果只为了在进程内部是用的话使用临界区会带来速度上的优势并能够减少资源占用量。 通过互斥量可以指定资源被独占的方式使用，但如果有下面一种情况通过互斥量就无法处理，比如现在一位用户购买了一份三个并发访问许可的数据库系统，可以根据用户购买的访问许可数量来决定有多少个线程/进程能同时进行数据库操作，这时候如果利用互斥量就没有办法完成这个要求，信号量对象可以说是一种资源计数器。 3、信号量：为控制一个具有有限数量用户资源而设计。它允许多个线程在同一时刻访问同一资源，但是需要限制在同一时刻访问此资源的最大线程数目。互斥量是信号量的一种特殊情况，当信号量的最大资源数=1就是互斥量了。\n优点：适用于对Socket（套接字）程序中线程的同步。\n缺点:\n信号量机制必须有公共内存，不能用于分布式操作系统，这是它最大的弱点； 信号量机制功能强大，但使用时对信号量的操作分散， 而且难以控制，读写和维护都很困难，加重了程序员的编码负担； 核心操作P-V分散在各用户程序的代码中，不易控制和管理，一旦错误，后果严重，且不易发现和纠正。 4、事件： 用来通知线程有一些事件已发生，从而启动后继任务的开始。\n优点：事件对象通过通知操作的方式来保持线程的同步，并且可以实现不同进程中的线程同步操作。\n*线程同步的方式有哪些？*\n一个回答：\n线程同步是两个或多个共享关键资源的线程的并发执行。应该同步线程以避免关键的资源使用冲突。操作系统一般有下面三种线程同步的方式：\n互斥量(Mutex)：采用互斥对象机制，只有拥有互斥对象的线程才有访问公共资源的权限。因为互斥对象只有一个，所以可以保证公共资源不会被多个线程同时访问。比如 Java 中的 synchronized 关键词和各种 Lock 都是这种机制。 信号量(Semaphore) ：它允许同一时刻多个线程访问同一资源，但是需要控制同一时刻访问此资源的最大线程数量。 事件(Event) :Wait/Notify：通过通知操作的方式来保持多线程同步，还可以方便的实现多线程优先级的比较操作。 另一个回答：\n1、临界区：当多个线程访问一个独占性共享资源时，可以使用临界区对象。拥有临界区的线程可以访问被保护起来的资源或代码段，其他线程若想访问，则被挂起，直到拥有临界区的线程放弃临界区为止，以此达到用原子方式操 作共享资源的目的。\n2、事件：事件机制，则允许一个线程在处理完一个任务后，主动唤醒另外一个线程执行任务。\n3、互斥量：互斥对象和临界区对象非常相似，只是其允许在进程间使用，而临界区只限制与同一进程的各个线程之间使用，但是更节省资源，更有效率。\n4、信号量：当需要一个计数器来限制可以使用某共享资源的线程数目时，可以使用“信号量”对象。\n区别：\n互斥量与临界区的作用非常相似，但互斥量是可以命名的，也就是说互斥量可以跨越进程使用，但创建互斥量需要的资源更多，所以如果只为了在进程内部是用的话使用临界区会带来速度上的优势并能够减少资源占用量 。因为互斥量是跨进程的互斥量一旦被创建，就可以通过名字打开它。 互斥量，信号量，事件都可以被跨越进程使用来进行同步数据操作。 *什么是临界区，如何解决冲突？*\n每个进程中访问临界资源的那段程序称为临界区，一次仅允许一个进程使用的资源称为临界资源。\n解决冲突的办法：\n如果有若干进程要求进入空闲的临界区，一次仅允许一个进程进入，如已有进程进入自己的临界区，则其它所有试图进入临界区的进程必须等待； 进入临界区的进程要在有限时间内退出。 如果进程不能进入自己的临界区，则应让出CPU，避免进程出现“忙等”现象。 *什么是死锁？死锁产生的条件？*\n什么是死锁：\n在两个或者多个并发进程中，如果每个进程持有某种资源而又等待其它进程释放它或它们现在保持着的资源，在未改变这种状态之前都不能向前推进，称这一组进程产生了死锁。通俗的讲就是两个或多个进程无限期的阻塞、相互等待的一种状态。\n死锁产生的四个必要条件：（有一个条件不成立，则不会产生死锁）\n互斥条件：一个资源一次只能被一个进程使用 请求与保持条件：一个进程因请求资源而阻塞时，对已获得资源保持不放 不剥夺条件：进程获得的资源，在未完全使用完之前，不能强行剥夺 循环等待条件：若干进程之间形成一种头尾相接的环形等待资源关系 如何处理死锁问题：\n解决死锁的方法可以从多个角度去分析，一般的情况下，有预防，避免，检测和解除四种。\n预防 是采用某种策略，限制并发进程对资源的请求，从而使得死锁的必要条件在系统执行的任何时间上都不满足。 避免则是系统在分配资源时，根据资源的使用情况提前做出预测，从而避免死锁的发生 检测是指系统设有专门的机构，当死锁发生时，该机构能够检测死锁的发生，并精确地确定与死锁有关的进程和资源。 解除 是与检测相配套的一种措施，用于将进程从死锁状态下解脱出来。 *进程调度策略有哪几种？*\n先来先服务：非抢占式的调度算法，按照请求的顺序进行调度。有利于长作业，但不利于短作业，因为短作业必须一直等待前面的长作业执行完毕才能执行，而长作业又需要执行很长时间，造成了短作业等待时间过长。另外，对I/O密集型进程也不利，因为这种进程每次进行I/O操作之后又得重新排队。\n短作业优先：非抢占式的调度算法，按估计运行时间最短的顺序进行调度。长作业有可能会饿死，处于一直等待短作业执行完毕的状态。因为如果一直有短作业到来，那么长作业永远得不到调度。\n最短剩余时间优先：最短作业优先的抢占式版本，按剩余运行时间的顺序进行调度。 当一个新的作业到达时，其整个运行时间与当前进程的剩余时间作比较。如果新的进程需要的时间更少，则挂起当前进程，运行新的进程。否则新的进程等待。\n时间片轮转：将所有就绪进程按 FCFS 的原则排成一个队列，每次调度时，把 CPU 时间分配给队首进程，该进程可以执行一个时间片。当时间片用完时，由计时器发出时钟中断，调度程序便停止该进程的执行，并将它送往就绪队列的末尾，同时继续把 CPU 时间分配给队首的进程。\n时间片轮转算法的效率和时间片的大小有很大关系：因为进程切换都要保存进程的信息并且载入新进程的信息，如果时间片太小，会导致进程切换得太频繁，在进程切换上就会花过多时间。 而如果时间片过长，那么实时性就不能得到保证。\n优先级调度：为每个进程分配一个优先级，按优先级进行调度。为了防止低优先级的进程永远等不到调度，可以随着时间的推移增加等待进程的优先级。\n多级反馈队列，根据队列预测未来。 比如不知道进程的运行时间，不知道运行密集型，还是交互型。我们想要把交互型的响应时间要短，运行密集型调度时间要少。\n*什么是分页？*\n把内存空间划分为大小相等且固定的块，作为主存的基本单位。因为程序数据存储在不同的页面中，而页面又离散的分布在内存中，因此需要一个页表来记录映射关系，以实现从页号到物理块号的映射。\n访问分页系统中内存数据需要两次的内存访问 (一次是从内存中访问页表，从中找到指定的物理块号，加上页内偏移得到实际物理地址；第二次就是根据第一次得到的物理地址访问内存取出数据)。\nhttps://segmentfault.com/img/bVcSKjQ\n什么是分段？\n分页是为了提高内存利用率，而分段是为了满足程序员在编写代码的时候的一些逻辑需求(比如数据共享，数据保护，动态链接等)。\n分段内存管理当中，地址是二维的，一维是段号，二维是段内地址；其中每个段的长度是不一样的，而且每个段内部都是从0开始编址的。由于分段管理中，每个段内部是连续内存分配，但是段和段之间是离散分配的，因此也存在一个逻辑地址到物理地址的映射关系，相应的就是段表机制。\nhttps://segmentfault.com/img/bVcSKjR\n*分页和分段有什区别？*\n分页对程序员是透明的，但是分段需要程序员显式划分每个段。 分页的地址空间是一维地址空间，分段是二维的。 页的大小不可变，段的大小可以动态改变。 分页主要用于实现虚拟内存，从而获得更大的地址空间；分段主要是为了使程序和数据可以被划分为逻辑上独立的地址空间并且有助于共享和保护。 另一个回答：\n共同点\n：\n分页机制和分段机制都是为了提高内存利用率，减少内存碎片。 页和段都是离散存储的，所以两者都是离散分配内存的方式。但是，每个页和段中的内存是连续的。 区别\n：\n页的大小是固定的，由操作系统决定；而段的大小不固定，取决于我们当前运行的程序。 分页仅仅是为了满足操作系统内存管理的需求，而段是逻辑信息的单位，在程序中可以体现为代码段，数据段，能够更好满足用户的需要 著作权归所有 原文链接：https://javaguide.cn/cs-basics/operating-system/operating-system-basic-questions-01.html\n*什么是交换空间？*\n操作系统把物理内存(physical RAM)分成一块一块的小内存，每一块内存被称为页(page)。当内存资源不足时，Linux把某些页的内容转移至硬盘上的一块空间上，以释放内存空间。硬盘上的那块空间叫做交换空间(swap space),而这一过程被称为交换(swapping)。物理内存和交换空间的总容量就是虚拟内存的可用容量。\n用途：\n物理内存不足时一些不常用的页可以被交换出去，腾给系统。 程序启动时很多内存页被用来初始化，之后便不再需要，可以交换出去。 *页面替换算法有哪些？*\n在程序运行过程中，如果要访问的页面不在内存中，就发生缺页中断从而将该页调入内存中。此时如果内存已无空闲空间，系统必须从内存中调出一个页面到磁盘对换区中来腾出空间。\n包括以下算法：\n最佳算法：所选择的被换出的页面将是最长时间内不再被访问，通常可以保证获得最低的缺页率。这是一种理论上的算法，因为无法知道一个页面多长时间不再被访问。 先进先出：选择换出的页面是最先进入的页面。该算法将那些经常被访问的页面也被换出，从而使缺页率升高。 LRU：虽然无法知道将来要使用的页面情况，但是可以知道过去使用页面的情况。LRU 将最近最久未使用的页面换出。为了实现 LRU，需要在内存中维护一个所有页面的链表。当一个页面被访问时，将这个页面移到链表表头。这样就能保证链表表尾的页面是最近最久未访问的。因为每次访问都需要更新链表，因此这种方式实现的 LRU 代价很高。 时钟算法：时钟算法使用环形链表将页面连接起来，再使用一个指针指向最老的页面。它将整个环形链表的每一个页面做一个标记，如果标记是0，那么暂时就不会被替换，然后时钟算法遍历整个环，遇到标记为1的就替换，否则将标记为0的标记为1。 *什么是缓冲区溢出？有什么危害？*\n缓冲区溢出是指当计算机向缓冲区填充数据时超出了缓冲区本身的容量，溢出的数据覆盖在合法数据上。\n危害有以下两点：\n程序崩溃，导致拒绝额服务 跳转并且执行一段恶意代码 造成缓冲区溢出的主要原因是程序中没有仔细检查用户输入。\n*什么是虚拟内存？*\n虚拟内存就是说，让物理内存扩充成更大的逻辑内存，从而让程序获得更多的可用内存。虚拟内存使用部分加载的技术，让一个进程或者资源的某些页面加载进内存，从而能够加载更多的进程，甚至能加载比内存大的进程，这样看起来好像内存变大了，这部分内存其实包含了磁盘或者硬盘，并且就叫做虚拟内存。\n*讲一讲IO多路复用？*\nIO多路复用是指内核一旦发现进程指定的一个或者多个IO条件准备读取，它就通知该进程。IO多路复用适用如下场合：\n当客户处理多个描述字时（一般是交互式输入和网络套接口），必须使用I/O复用。 当一个客户同时处理多个套接口时，而这种情况是可能的，但很少出现。 如果一个TCP服务器既要处理监听套接口，又要处理已连接套接口，一般也要用到I/O复用。 如果一个服务器即要处理TCP，又要处理UDP，一般要使用I/O复用。 如果一个服务器要处理多个服务或多个协议，一般要使用I/O复用。 与多进程和多线程技术相比，I/O多路复用技术的最大优势是系统开销小，系统不必创建进程/线程，也不必维护这些进程/线程，从而大大减小了系统的开销。 *硬链接和软链接有什么区别？*\n硬链接就是在目录下创建一个条目，记录着文件名与 inode 编号，这个 inode 就是源文件的 inode。删除任意一个条目，文件还是存在，只要引用数量不为 0。但是硬链接有限制，它不能跨越文件系统，也不能对目录进行链接。 符号链接文件保存着源文件所在的绝对路径，在读取时会定位到源文件上，可以理解为 Windows 的快捷方式。当源文件被删除了，链接文件就打不开了。因为记录的是路径，所以可以为目录建立符号链接。 中断的处理过程?\n保护现场：将当前执行程序的相关数据保存在寄存器中，然后入栈。 开中断：以便执行中断时能响应较高级别的中断请求。 中断处理 关中断：保证恢复现场时不被新中断打扰 恢复现场：从堆栈中按序取出程序数据，恢复中断前的执行状态。 *中断和轮询有什么区别？*\n轮询：CPU对特定设备轮流询问。中断：通过特定事件提醒CPU。 轮询：效率低等待时间长，CPU利用率不高。中断：容易遗漏问题，CPU利用率不高。 **什么是系统调用呢？**能不能详细介绍一下。\n介绍系统调用之前，我们先来了解一下用户态和系统态。\n根据进程访问资源的特点，我们可以把进程在系统上的运行分为两个级别：\n用户态(user mode) : 用户态运行的进程可以直接读取用户程序的数据。 系统态(kernel mode):可以简单的理解系统态运行的进程或程序几乎可以访问计算机的任何资源，不受限制。 说了用户态和系统态之后，那么什么是系统调用呢？\n我们运行的程序基本都是运行在用户态，如果我们调用操作系统提供的系统态级别的子功能咋办呢？那就需要系统调用了！\n也就是说在我们运行的用户程序中，凡是与系统态级别的资源有关的操作（如文件管理、进程控制、内存管理等)，都必须通过系统调用方式向操作系统提出服务请求，并由操作系统代为完成。\n这些系统调用按功能大致可分为如下几类：\n设备管理。完成设备的请求或释放，以及设备启动等功能。 文件管理。完成文件的读、写、创建及删除等功能。 进程控制。完成进程的创建、撤销、阻塞及唤醒等功能。 进程通信。完成进程之间的消息传递或信号传递等功能。 内存管理。完成内存的分配、回收以及获取作业占用内存区大小及地址等功能。 著作权归所有 原文链接：https://javaguide.cn/cs-basics/operating-system/operating-system-basic-questions-01.html\n操作系统的内存管理主要是做什么？\n操作系统的内存管理主要负责内存的分配与回收（malloc 函数：申请内存，free 函数：释放内存），另外地址转换也就是将逻辑地址转换成相应的物理地址等功能也是操作系统内存管理做的事情\n*局部性原理*\n局部性原理是虚拟内存技术的基础，正是因为程序运行具有局部性原理，才可以只装入部分程序到内存就开始运行。\n以下内容摘自《计算机操作系统教程》 第 4 章存储器管理。\n早在 1968 年的时候，就有人指出我们的程序在执行的时候往往呈现局部性规律，也就是说在某个较短的时间段内，程序执行局限于某一小部分，程序访问的存储空间也局限于某个区域。\n局部性原理表现在以下两个方面：\n时间局部性 ：如果程序中的某条指令一旦执行，不久以后该指令可能再次执行；如果某数据被访问过，不久以后该数据可能再次被访问。产生时间局部性的典型原因，是由于在程序中存在着大量的循环操作。 空间局部性 ：一旦程序访问了某个存储单元，在不久之后，其附近的存储单元也将被访问，即程序在一段时间内所访问的地址，可能集中在一定的范围之内，这是因为指令通常是顺序存放、顺序执行的，数据也一般是以向量、数组、表等形式簇聚存储的。 时间局部性是通过将近来使用的指令和数据保存到高速缓存存储器中，并使用高速缓存的层次结构实现。空间局部性通常是使用较大的高速缓存，并将预取机制集成到高速缓存控制逻辑中实现。虚拟内存技术实际上就是建立了 “内存一外存”的两级存储器的结构，利用局部性原理实现髙速缓存\n著作权归所有 原文链接：https://javaguide.cn/cs-basics/operating-system/operating-system-basic-questions-01.html\n什么是虚拟内存(Virtual Memory)?\n这个在我们平时使用电脑特别是 Windows 系统的时候太常见了。很多时候我们使用了很多占内存的软件，这些软件占用的内存可能已经远远超出了我们电脑本身具有的物理内存。为什么可以这样呢？ 正是因为 虚拟内存 的存在，通过 虚拟内存 可以让程序拥有超过系统物理内存大小的可用内存空间。另外，虚拟内存为每个进程提供了一个一致的、私有的地址空间，它让每个进程产生了一种自己在独享主存的错觉（每个进程拥有一片连续完整的内存空间）。这样会更加有效地管理内存并减少出错。\n虚拟内存是计算机系统内存管理的一种技术，我们可以手动设置自己电脑的虚拟内存。不要单纯认为虚拟内存只是“使用硬盘空间来扩展内存“的技术。虚拟内存的重要意义是它定义了一个连续的虚拟地址空间，并且 把内存扩展到硬盘空间。推荐阅读：《虚拟内存的那点事儿》open in new window\n维基百科中有几句话是这样介绍虚拟内存的。\n虚拟内存 使得应用程序认为它拥有连续的可用的内存（一个连续完整的地址空间），而实际上，它通常是被分隔成多个物理内存碎片，还有部分暂时存储在外部磁盘存储器上，在需要时进行数据交换。与没有使用虚拟内存技术的系统相比，使用这种技术的系统使得大型程序的编写变得更容易，对真正的物理内存（例如 RAM）的使用也更有效率。目前，大多数操作系统都使用了虚拟内存，如 Windows 家族的“虚拟内存”；Linux 的“交换空间”等。From:https://zh.wikipedia.org/wiki/虚拟内存\n著作权归所有 原文链接：https://javaguide.cn/cs-basics/operating-system/operating-system-basic-questions-01.html\n虚拟内存技术的实现呢？\n虚拟内存的实现需要建立在离散分配的内存管理方式的基础上。 虚拟内存的实现有以下三种方式：\n请求分页存储管理 ：建立在分页管理之上，为了支持虚拟存储器功能而增加了请求调页功能和页面置换功能。请求分页是目前最常用的一种实现虚拟存储器的方法。请求分页存储管理系统中，在作业开始运行之前，仅装入当前要执行的部分段即可运行。假如在作业运行的过程中发现要访问的页面不在内存，则由处理器通知操作系统按照对应的页面置换算法将相应的页面调入到主存，同时操作系统也可以将暂时不用的页面置换到外存中。 请求分段存储管理 ：建立在分段存储管理之上，增加了请求调段功能、分段置换功能。请求分段储存管理方式就如同请求分页储存管理方式一样，在作业开始运行之前，仅装入当前要执行的部分段即可运行；在执行过程中，可使用请求调入中断动态装入要访问但又不在内存的程序段；当内存空间已满，而又需要装入新的段时，根据置换功能适当调出某个段，以便腾出空间而装入新的段。 请求段页式存储管理 这里多说一下？很多人容易搞混请求分页与分页存储管理，两者有何不同呢？\n请求分页存储管理建立在分页管理之上。他们的根本区别是是否将程序所需的全部地址空间都装入主存，这也是请求分页存储管理可以提供虚拟内存的原因，我们在上面已经分析过了。\n它们之间的根本区别在于是否将一作业的全部地址空间同时装入主存。请求分页存储管理不要求将作业全部地址空间同时装入主存。基于这一点，请求分页存储管理可以提供虚存，而分页存储管理却不能提供虚存。\n不管是上面那种实现方式，我们一般都需要：\n一定容量的内存和外存：在载入程序的时候，只需要将程序的一部分装入内存，而将其他部分留在外存，然后程序就可以执行了； 缺页中断：如果需执行的指令或访问的数据尚未在内存（称为缺页或缺段），则由处理器通知操作系统将相应的页面或段调入到内存，然后继续执行程序； 虚拟地址空间 ：逻辑地址到物理地址的变换。 著作权归所有 原文链接：https://javaguide.cn/cs-basics/operating-system/operating-system-basic-questions-01.html\n什么是银行家算法？是不是可以把其他算法都拉出来看看\n银行家算法是一种最有代表性的避免死锁的算法。在避免死锁方法中允许进程动态地申请资源，但系统在进行资源分配之前，应先计算此次分配资源的安全性，若分配不会导致系统进入不安全状态，则分配，否则等待。为实现银行家算法，系统必须设置若干数据结构。安全的状态指的是一个进程序列{P1,P2,\u0026hellip;Pn}，对于每一个进程Pi，它以后尚需要的资源不大于当前资源剩余量和其余进程所占有的资源量之和。\n参考：\n","permalink":"https://omgkill.github.io/post/system/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93/","tags":["operation system","knowledge summary"],"title":"操作系统面试题"},{"categories":["linux"],"contents":" 输出类型\n/dev/stderr 代表标准错误 /dev/stdin 输出可以用 - /dev/stdout 代表标准输出 输出符号意义 \u0026gt; 表示先清空文件，然后再写内容 \u0026gt;\u0026gt; 表示内容追加到现有文件的尾部\n/dev/null 是一个特殊的设备文件，它接收的任何数据都会丢弃\n将脚本内部的文本块进行重定向\n1#! /bin/base 2cat \u0026lt;\u0026lt;EOF\u0026gt;\u0026gt; log.txt 3LOG FILE HEADER 4this is a test log file 5Function: System statics 6EOF \u0026lt; 从文件读取stdin \u0026gt; 操作符，用于截断模式的文件写入 \u0026gt;\u0026gt; 操作追加模式的文件写入 find 命令\n11. 查找普通模式 find . -name(-iname 忽略大小写) \u0026#39;aa.txt\u0026#39; 2 find . -name \u0026#39;a*\u0026#39; 3 点代表当前目录，两个点代表父母目录，/ 代表根目录 4 2. 更好的方法 5 查找目录 find . -type d -print 6 查找文件 find . -type f -print 7 如果想看更多，如权限等。加 |xargs ls -l 说明：https://www.cnblogs.com/kilometerwine/p/9872265.html 8 3. 支持 与/或逻辑 find . \\(-name \u0026#39;*.txt\u0026#39; -o -name \u0026#39;*.pdf\u0026#39;\\) -print 9 -a 就 10 4. find /home/users -path \u0026#39;*/slynux/*\u0026#39; -name \u0026#39;*.txt\u0026#39; -print 11 5. 基于正则表达式 12 find . -regex \u0026#39;.*\\.(py\\|sh\\)$\u0026#39; 13 -iregex 忽略大小写 14 find . -iregex \u0026#39;.*\\(\\.py\\|\\.sh\\)$\u0026#39; 15 6. 否定参数 16 find . ! -name \u0026#34;*.txt\u0026#34; -print 17 7. 基于目录深度的搜索 18 find -L /proc -maxdepth 1 -name \u0026#39;bundlemaker.def\u0026#39; 2 \u0026gt; /dev/null 19 8. 文件类型 普通文件\u0026lt;=\u0026gt; f | 符号链接 \u0026lt;=\u0026gt; l | 目录 -\u0026gt; d | 字符设备 -\u0026gt; c 20 块设备 -\u0026gt; b | 套接字 -\u0026gt; s | FIFO -\u0026gt; p 21 9. 根据 文件的时间戳进行搜索 22 访问时间 -atime 23 修改时间 -mtime 24 变化时间 -ctime 25 7天内访问 find . -type f -atime -7 -print 26 7天前访问 find . -type f -atime +7 -print 27 10. 记录文件大小 28 find . -type f -size +2k 29 11. 利用find执行相应操作 30 find . -type f -name \u0026#34;*.swp\u0026#34; -delete grep\n1 1. 匹配多个文件 2 grep \u0026#34;match.text\u0026#34; file1 file2 file 3 3 2. 着重标记 4 grep --color=auto world filename 5 3. 使用正则 6 egrep \u0026#34;[a-z]+\u0026#34; filename 7 4. 只输出匹配到的文本 8 egrep -o \u0026#34;[a-z]+\\.\u0026#34; 9 5. 打印不匹配结果 10 grep -v match_patttern filename 11 6. 统计匹配的文本行数 12 grep -c \u0026#34;text\u0026#34; filename 13 7. 统计匹配数量 14 egrep -o \u0026#34;{0-9}\u0026#34; | wc -l 15 8. 打印匹配所在行 16 grep linux -n sample1.txt 17 9. 匹配模式所在的文件 18 grep -l \u0026#39;linux\u0026#39; simaple.txt simple2.txt （如果相反是大写） 19 10. 递归搜索多个文件 20 grep \u0026#34;txt\u0026#34; . -R -n 同等与 find . -type f | xarge grep \u0026#34;test _function()\u0026#34; . -R -n 21 或 find . -type f | xargs grep \u0026#34;test_function()\u0026#34; 22 11. 忽略大小写 23 echo hello world | grep -i \u0026#34;HELLO\u0026#34; 24 12. 匹配多个模式 25 grep -e \u0026#34;pattern1\u0026#34; -e \u0026#34;pattern2\u0026#34; 26 匹配到一个，就是一行 27 echo this is a line of text | grep -o -e \u0026#34;this\u0026#34; -e \u0026#34;line\u0026#34; 28 将多个模式放到文件中 29 grep -f pattern_filesource_filename 30 13. grep 可以在搜索中使用通配符或排除某些文件 31 使用--include选项在目录中递归搜索所有的.c 和 .cpp 文件： 32 grep \u0026#34;main()\u0026#34; . -r --include *.{c,cpp} 33 使用--exclud在搜索过程中排除所有的README文件 34 grep \u0026#34;main()\u0026#34; . -r --exclude \u0026#34;README\u0026#34; 35 选项--exclude-dir 可以排除目录 36 grep main . -r -exclude-dir cvs 37 14. 使用0值字节后缀的xargs 与 grep 38 grep \u0026#34;test\u0026#34; file* -lZ | xargs -0 rm 39 15. grep 静默输出, 只获取是否匹配成功 40 一个ssh 41 #!/bin/base 42 # 文件名：silent_grep.sh 43 #用途：测试文件是否包含特定的文本内容 44 if [$# -ne 2]; then 45 echo \u0026#34;Usage:$0 match_text filename*\u0026#34; 46 exit 1 47 fi 48 match_text=$1 49 filename=$2 50 grep -q \u0026#34;$match_text\u0026#34; $filename 51 if [$? -eq 0]; then 52 echo \u0026#34;the text exists in the file\u0026#34; 53 else 54 echo \u0026#34;text does not exists in the file\u0026#34; 55 fi 56 执行命令 57 ./silent_grep.sh Student student_data.txt 58 16. 打印出匹配文本之前或之后的行 59 选项-A可以打印匹配结果之后的行 60 seq 10 | grep 5 -A 3 正则表达式\n1 1. 匹配任意单词的正则表达式 2 ( +[a-zA-Z]+ +) 3 2. 匹配句尾或是都前的单词 4 ( +[a-zA-Z]+[?,.]? +) 5 6 [?,.]? 表示仅需要匹配问号、逗号或点号中的一个 7 3. [[:digit:]] 表示数字 使用cut按列切分文件\n1cut命令可以按列，而不是按行来切分文件。该命令可用于处理使用使用固定宽度字段的文件。CSV文件或是由空格分隔的文件 2 31. 选项 -f 可以指定要提取的字段 4 cut -f FIELD_LIST filename 5 $cut -f2,3 filename 62. --complement 选项显示出没有被-f 指定的那些字段 7 cut -f3 --complement student_data.txt 83. 选项-d 能够设置分隔符 9 cut -f2 -d\u0026#34;;\u0026#34; delimited_data.txt 104. 指定字段的字符或字节范围 11 N- 从第N个字节、字符或字段开始到行尾 12 N-M 从第N个字节、字符或字段开始到第M个 13 -M 从第1个字节，到第M个 145. 指定字段的字符或字节范围 15 -b 表示字节 16 -c 表示字符 17 -f 用于定义字段 186. --output -delimiter 可以指定输出分隔符 19 cut range_fields.txt -c-2，6-9 --output-delimiter \u0026#34;,\u0026#34; 使用sed替换文本\n11. 替换 2 sed \u0026#39;s/pattern/replace_string/\u0026#39; file 3 cat etc/passwd/ | cut -d : -f1,3 | sed \u0026#39;s/:/ - UID: /\u0026#39; 42. 选项-i 会使得sed用修改后的数据替换原文件 5 $sed -i \u0026#39;s/text/replace\u0026#39; file 63. g标记可以使sed执行全局替换 7 /#g 标记可以使sed替换第N次出现的匹配： 8 - $ echo thisthisthisthis | sed \u0026#39;s/this/THIS/2g\u0026#39; 9 thisTHISTHISTHIS 10 - $ echo thisthisthisthis | sed \u0026#39;s/this/THIS/3g\u0026#39; 11 thisthisTHISTHIS 124. sed命令会将s之后的字符视为命令分隔符 13 sed \u0026#39;s:text:replace:g\u0026#39; 14 转义 ： sed \u0026#39;s|te\\|xt|replace|g\u0026#39; 155. 正则表达式 -- 移除空行 ^$ 匹配空行， /d 执行删除 16 sed \u0026#39;/^$d\u0026#39; file 176. 直接在文件中替换 18 sed \u0026#39;s/PATTERN/replacement\u0026#39; -i filename 19 sed -i \u0026#39;s/\\b[0-9]\\{3\\}\\b/NUMBER/g\u0026#39; sed_data.txt 20 其中\\b 表示单词边界 21 - 还可以先不替换源文件，新建一个 22 sed -i.bak \u0026#39;s/abc/def/\u0026#39; file 23 7. 已匹配字符串 标记(\u0026amp;) 24 $echo this is an example | sed \u0026#39;s/\\w\\+/[\u0026amp;]/g\u0026#39; 25 [this] [is] [an] [example] 26 \\w\\+ 匹配每一个单词 27 8. 字符串匹配标记 28 $echo this is digit 7 in a number | sed \u0026#39;s/digit \\([0-9]\\)/\\1\u0026#39; 29 this is 7 in a number 30 \\(pattern\\) 用于匹配子串 31 \\1 匹配到的第一个字段 32 - secho seven EIGHT | \u0026#39;s/\\([a-z]\\+\\) \\([A-Z]\\+\\)/\\2 \\1/\u0026#39; 33 9. 组合多个表达式 34 sed \u0026#39;expression\u0026#39; | sed \u0026#39;expression\u0026#39; 35 等同于，sed \u0026#39;expression;expression\u0026#39; 36 或者： sed -e \u0026#39;expression\u0026#39; -e \u0026#39;expression\u0026#39; 37 示例： 38 echo abc | sed \u0026#39;s/a/A/\u0026#39; sed \u0026#39;s/c/C/\u0026#39; 39 10. sed 表达式通常用单引号来引用，shell会在调用sed前先扩展双引号内容 40 $text = hello 41 $echo hello world | sed \u0026#34;s/$test/HELLO\u0026#34; 42 HELLO world 43 11. sed /s/pattern/replace/p, /p 会把匹配到的行再输出一遍，也就时匹配到的行会重复输出 44 12. sed -n /s/pattern/replace/p -n 与 /p 就只输出匹配到的行 45 13. tac logs/smartfox.log | sed -n \u0026#39;/com.elex.cok.common.core.ThreadTask/ {/50*/ s/503/\u0026amp;\\n\\n\\n/;p}\u0026#39; | less -- 相当于 tac file | sed -n \u0026#39;/A/ {B/ s/C/repace/;p}\u0026#39; (;p - 默认输出) 46 14. 参考网址https://www.cnblogs.com/ggjucheng/archive/2013/01/13/2856901.html 使用awk进行高级文本处理\n1awk 脚本的结构如下： 2- awk \u0026#39;BEGIN{ print \u0026#34;start\u0026#34;} pattern {commands} END {print \u0026#34;end\u0026#34;}\u0026#39; file 3- awk \u0026#39;BEGIN {statements} {statements} END {end statements}\u0026#39; 4- awk \u0026#34;BEGIN {i =0} {i++} END {print i}\u0026#34; filename 51. 中间{} 默认执行{print} 62. print 能够接受参数，这些参数以逗号分隔 7 echo | awk \u0026#39;{var1=\u0026#34;v1\u0026#34;;var2=\u0026#34;v2\u0026#34;;var3=\u0026#34;v3\u0026#34;;print var1,var2,var3;}\u0026#39; 83. 特殊变量 9 - NR: 表示记录编号，当awk将行作为记录时，该变量相当于当前行号 10 - NF: 表示字段数量，在处理当前记录时，相当于字段数量，默认的字段分隔符是空格 11 - $0: 该变量包含当前记录的文本内容 12 - $1: 该变量包含第一个字段的文本内容 13 - $2: 该变量包含第二个字段的文本内容 14 153.awk使用正则 16 seq 10 | awk \u0026#39;BEGIN{print \u0026#34;start\u0026#34;} /6.*/ {print} END{print \u0026#34;end\u0026#34;}\u0026#39; 174. 例子 18 echo -e \u0026#34;line1 f2 f3\\nline2 f4 f5\\nline3 f6 f7\u0026#34; | \\ 19 awk \u0026#39;{ 20 print \u0026#34;Line no:\u0026#34;NR\u0026#34;,No of fields:\u0026#34;NF, \u0026#34;$0=\u0026#34;$0, 21 \u0026#34;$1=\u0026#34;$1,\u0026#34;$2=\u0026#34;$2,\u0026#34;$3=\u0026#34;$3 22 }\u0026#39; 235. 打印每一行的第二和第三个字段 24 awK \u0026#39;{print $3,$2}\u0026#39; file 256. 我们可以使用NR统计文件行数 26 awk \u0026#39;END {print NR}\u0026#39; file 277. 借助选项-v， 我们可以将外部值传递给awk： 28 $VAR=10000 29 $ echo | awk -v VARIABLE = $VAR \u0026#39;{print VARIABLE}\u0026#39; 308. 还有一种灵活的方法可以将多个外部变量传递给awk 31 $ var1 = \u0026#34;Variable1\u0026#34;; var2 = \u0026#34;Variable2\u0026#34; 32 $ echo | awk \u0026#39;{print v1, v2}\u0026#39; v1=$var1 v2 = $var2 33 当输入来自于文件而非标准输入时，使用下列命令 34 $ awk \u0026#39;{print v1,v2}\u0026#39; v1=$var1 v2=$var2 filename 359. 用getline读取行 36 seq 5 | awk \u0026#39;BEGIN {getline;print \u0026#34;Read ahead first line\u0026#34;, $0}\u0026#39; {print $0} 3710. 使用过滤模式对awk处理的行进行过滤 38 $ awk \u0026#39;NR \u0026lt; 5\u0026#39; # 行号小于5的行 39 $ awk \u0026#39;NR==1, NR==4\u0026#39; # 行号在1到5之间的行 40 $ awk \u0026#39;/linux/\u0026#39; #包含模式为linux的行（可以用正则表达式来指定模式） 41 $ awk \u0026#39;!/linux/\u0026#39; # 不包含模式为linux的行 4211. 设置字段分隔符 43 awk -F: \u0026#39;{print $NF}\u0026#39; /etc/passwd 44 或者 awk \u0026#39;BEGIN {FS=\u0026#34;:\u0026#34;} {print $NF}\u0026#39; /etc/passwd 4512. 从awk 中读取命令输出 46 “command” | getline output; 47 $awk \u0026#39;BEGIN {FS=\u0026#34;:\u0026#34;} {\u0026#34;grep root /etc/passwd\u0026#34; | getline; print $1,$6}\u0026#39; 4813. 在awk中使用循环 49 awk \u0026#39;BEGIN {FS=\u0026#34;:\u0026#34;} {nam[$1]=$5}} END{for {i in name} {print i,nam[i]}}\u0026#39; /etc/passwd 5014. 使用if 51\tnetstat -tanp | awk \u0026#39;{if ($2 \u0026gt; 0 || $3 \u0026gt; 0) print $0}\u0026#39; 5215. awk内建的字符串处理函数 53 - length(string) : 返回字符串string的长度 54 - index(string,serach_string) : 返回search_string 在字符串string出现的位置 55 - split(string, array, delimiter):以delimiter作为分隔符，分割字符串string，将生成的字符串存入数组array 56 - substr(string, start-position, end-position) : 返回字符串string中以start-position 和 end-position 作为起止位置的字符串 57 - sub(regex, replancement_str, string): 将正则表达式regex匹配到的第一处内容替换成replacement_str 58 - gsub(regex, replacement_str, string) : 和sub()类似。不过该函数会替换正则表达式 regex匹配到的所有内容 59 - match(regex, string) : 检查正则表达式regex是否能够在字符串string中找到匹配。如果能够找到，返回非0值；否则，返回0. match() 有两个相关的特殊变量，分别是RSTART 和 RLENGTH。变量RSTATRTv包含了匹配内容的起止位置，而变量RLENGTH包含了匹配内容的长度 6016. 更多例子 61\thttps://blog.csdn.net/weixin_39953236/article/details/112127491 用tr进行转换\n1tr 是translate（转换）的简写 2 1. tr [options] set1 set2 3 2. 要将输入中的字符由大写转换为小写，可以使用下面的命令 4 echo \u0026#34;HELLO WHO IS THIS\u0026#34; | tr \u0026#39;A-Z\u0026#39; \u0026#39;a-z\u0026#39; 5 hello who is this 6 3. tr 进行加密和解密 7 echo 12345 | tr \u0026#39;0-9\u0026#39; \u0026#39;9876543210\u0026#39; 8 87654 # 已加密 9 echo 87654 | tr \u0026#39;9876543210\u0026#39; \u0026#39;0-9\u0026#39; 10 12345 # 已解密 11 4. 用tr删除字符 12 cat file.txt | tr -d \u0026#39;[set1]\u0026#39; 13 例如： 14 echo \u0026#34;Hello 123 world 456\u0026#34; | tr -d \u0026#39;0-9\u0026#39; 15 hello world 16 5. 字符组补集 17 tr -c \\[set1\\] [set2] 18 - 从输入文本中删除不在补集中的所有字符 19 echo hello 1 char 2 next 4 | tr -d -c \u0026#39;0-9 \\n\u0026#39; 20 124 21 - 不在set1中的字符替换成空格 22 echo hello 1 char 2 next 4 | tr -c \u0026#39;0-9\u0026#39; \u0026#39;\u0026#39; 23 1 2 4 24 - 删除多余的空格 25 tr -s \u0026#39; \u0026#39; 26 - 删除多余的换行符 27 tr -s \u0026#39;\\n\u0026#39; 28 - cat sum.txt | echo $[ $(tr \u0026#39;\\n\u0026#39; \u0026#39;+\u0026#39; ) 0 ] 29 30 - 包含字母和数字的文件， 计算数字之和 31 cat test.txt | tr -d [a-z] | echo \u0026#34;total: $[$(tr \u0026#39; \u0026#39; \u0026#39;+\u0026#39;\u0026#39;)]\u0026#34; 32 - 字符类 33 alnum : 字母和数字 34 alpha : 字母 35 cntrl : 控制（非打印）字符 36 digit : 数字 37 graph : 图形字符 38 lower : 小写字母 39 print : 可打印字符 40 punct : 标点符号 41 space : 空白字符 42 upper : 大写字母 43 xdigit : 十六进制字符 44 45 可以按照下面的方式选择所需的字符类 46 tr [:class:] [:class:] 47 例如 : 48 tr \u0026#39;[:lower:]\u0026#39; \u0026#39;[:upper:]\u0026#39; 统计特定文件中词频\n1if [$# -ne 1]; 2then 3 echo \u0026#34;Usage: $0 filename\u0026#34;; 4 exit -1 5fi 6 7filename=$1 8egrep -o \u0026#34;\\b[[:alpha:]]+\\b\u0026#34; $filename | \\ 9 awk \u0026#39;{ count[$0]++ } 10 END{ printf{\u0026#34;%-14s%s\\n\u0026#34;,\u0026#34;World\u0026#34;,\u0026#34;count\u0026#34;}}\u0026#39; ; 11 for(ind in count) 12 { printf(\u0026#34;%-14s%d\\n\u0026#34;,ind,count[ind]); 13 } 14- 可以利用tr命令将大写单词和非大写单词合计为一个单词，然后用sort命令排序输出： 15 egrep -o \u0026#34;\\b[[:alpha:]]+\\b\u0026#34; $filename | tr [A-Z] [a-z] | \\ 16 awk \u0026#39;{ count[$0]++ }\u0026#39; 17 END{ printf{\u0026#34;%-14s%s\\n\u0026#34;,\u0026#34;World\u0026#34;,\u0026#34;count\u0026#34;} ; 18 for(ind in count) 19 { printf(\u0026#34;%-14s%d\\n\u0026#34;,ind,count[ind]); 20 } 21 }\u0026#39; | sort 例子\n11. cat sample.js | \\ 2 tr -d \u0026#39;\\n\\t\u0026#39; | tr -s \u0026#39; \u0026#39; \\ 3 | sed \u0026#39;s:/\\*.*\\*/::g\u0026#39; \\ 4 | sed \u0026#39;s/ \\?\\([{}();,:]\\) \\?/\\1/g\u0026#39; 52. 打印从M行到N行之间的文本： 6 $ awk \u0026#39;NR==M, NR==N\u0026#39; filename 7 例如： 8 seq 100 | awk \u0026#39;NR==4,NR==6\u0026#39; 93. 打印位于模式start_pattern 与 end_pattern之间的文本 10 $ awk \u0026#39;/start_pattern/, /end_pattern/\u0026#39; filename 11 awk \u0026#39;/pa.*3/, /end/\u0026#39; section.txt 124. tac 命令, 倒序 13 - seq 5 | tac 14 - tac命令默认使用\\n作为行分隔符。使用-s 指定其他分隔符 15 echo \u0026#34;1,2\u0026#34; | tac-s, 16 - 使用awk的实现方式 17 seq 9 | \\ 18 awk \u0026#39;{ lifo[NR]=$0 } \\ 19 END {for(lno=NR;lno\u0026gt;-1;lno--){print lifo[lno]; } 20 }\u0026#39; 21 5. find . -name *.cpp -print0 | \\ 22 xargs -I{} -0 sed -i \u0026#39;s/Copyright/Copyleft/g\u0026#39; {} ","permalink":"https://omgkill.github.io/post/linux/linux%E5%91%BD%E4%BB%A4/","tags":["linux","shell"],"title":"Linux命令"},{"categories":["代码优化"],"contents":"单例模式 概念 确保一个类只有一个实例，并提供全局访问点\n例子说明 single\n是双重锁定，通过同步synchronzed确保多线程下只被一个线程执行，并在在同步前后判空，确保不会重复实例化该类。 voliatile确保执行的顺序不会改变。jvm会对代码进行优化，当执行顺序是这样就会出现问题。1、分配内存\u0026ndash;\u0026gt;2、把内存的引用赋值给instance\u0026ndash;\u0026gt;3、再把实例化的对象初始化到该内存下。(事实不一定这样，可以当一个场景)\n当线程A把2执行完，线程B判断instance是否为空，发现不为空，调用方法，这时就报nullpointException static模式\n有人说这是饿汉模式，服务一启动就加载。 enum\n枚举模式，好处：防止反射、反编译、返序列化、确保加载一个。在枚举初始化的时候实例化 好处 单例模式减少重复创建，节省空间，加载速度更快，节省时间。单例模式是无状态的\n命令模式 概念 将请求封装成对象，这可以让你使用不同的请求、队列，或者日志请求 来参数化其他对象。命令模式可以支持撤销操作\n例子 比如我有个遥控，只有三个按钮，打开、关闭、退回。然后我可以控制所有的电器。譬如，空调、电视、电扇、电脑、手机、冰箱、热水器等等。 但我在网上看到的例子是，client、commond、invoke、receiver，一点都不生动\n好处 调用者与被调用者完全解耦 命令的扩展性比较好 命令模式结合其他模式会更优秀：命令模式可以结合责任链模式，实现命令族解析任务；结合模板方法模式，则可以减少 Command子类的膨胀问题。 劣势 如果有大量命令，拿需要创建这么多命令 想法 我刚开始觉得调用者（invoke）特别多余，直接调用命令就行，何必再加一层。\n后来想了想，调用者可以做一些额外的操作。譬如日志、权限等等。\n外观模式 概念 提供一个统一的接口，用来访问子系统中的一群接口。外观定义了一个高层接口，让子类系统更容易使用优势\n例子说明 我们要开启一台电脑，需要哪些操作。首先接通电源、开启cpu、开启内存条、开启风扇、开启硬盘、开启显示屏、开启显卡等等。 但实际我们只需要点击电脑开关，就直接开机。电脑自己把这些元件都打开了。这就是外观模式\n好处 松散耦合 使得客户端和子系统之间解耦，让子系统内部的模块功能更容易扩展和维护；\n简单易用 客户端根本不需要知道子系统内部的实现，或者根本不需要知道子系统内部的构成， 它只需要跟Facade类交互即可。\n更好的划分访问层次 有些方法是对系统外的，有些方法是系统内部相互交互的使用的。 子系统把那些暴露给外部的功能集中到门面中，这样就可以实现客户端的使用， 很好的隐藏了子系统内部的细节。\n工厂模式 概念 工厂方法模式： 定义了一个创建对象的接口， 但由于子类决定要实例化的类是哪一个。工厂方法 让类把实例化推迟到子类\n例子说明 以pizza店说明,有两个pizz store，然后都本地化，有各自特色的pizza。但pizza的流程是一样的，只是具体的细节有区别。\n好处： 工厂模式可将这些创建对象的代码用栅栏围起来，就像你把所有的羊毛堆到眼前 一样，一旦围起来后，就可以保护这些创建对象的代码，如果让创建对象的代码 导出乱跑，就无法收集了。譬如要修改，就比较麻烦了 倒置原则\u0026ndash;依赖抽象，不要依赖具体的类 区别 简单工厂于工厂模式的区别： 一个简单工厂不能变更正在创建的产品。这个例子不错：https://blog.csdn.net/abc709272013/article/details/52654266 工厂模式 好处 工厂模式的好处就是把创建对象封装起来，减少对具体\n抽象工厂模式 概念 抽象工厂模式： 提供一个接口，用于创建相关或依赖对象的家族，而不需要 明确指定具体类\n例子说明 一个pizza店，需要各种原料。每个pizza的原料种类相同，但口味不一样。比如甜的奶酪 咸的奶酪，纯牛奶和酸牛奶，热的和冷的。那就需要给每个pizza创建唯一的原料工厂。\n与工厂模式区别 工厂模式是创建不同的对象，而抽象工厂更大，创建不同的一群对象。而且抽象工厂创建的对象是确定的。\n模板方法模式 概念 在一个方法中定义一个算法的骨架， 而将一些步骤延迟到子类中， 模板方法使得子类可以在不改变算法结构的情况下， 重新定义算法中的某些步骤。\n例子说明 比如做馒头和包子，都需要准备，揉面，蒸煮， 这三个步骤，且顺序是固定的。这个就可以用模板方法来做\n策略模式 概念 策略模式： 定义了算法族，分别封装起来，让它们之间可以相互替换\n优势 此模式让算法的变化独立于使用算法的客户 多用组合，少用继承 这个算法很常见，一个接口不同的实现就是策略模式啊 装饰者模式 概念 动态地将责任附加到对象上。若要扩展功能，装饰者提供了 比继承更有弹性的替代方案或者 可以这样说包装对象\n优点: CondimentDecorator继承Beverage，这是利用继承达到“类型匹配” 而不是继承获得“行为” 对扩展开放，对修改关闭 缺点 当一个对象依赖特定的类型，然后忽然导入，导致错误。插入装饰者必须小心谨慎 增加代码复杂度，使用者不知道到底导入了多少个装饰着 装饰者导致设计中出现许多小对象，如果过度使用，会让程序变得很复杂 例子 数据流\n父类：InputStream 装饰类：FilterInputStream 装饰者：BufferedInputStream, CheckedInputStream, CipherInputStream,DataInputStream, DeflaterInputStream, DigestInputStream,InflaterInputStream, LineNumberInputStream, ProgressMonitorInputStream,PushbackInputStream 被装饰者：AudioInputStream, ByteArrayInputStream, FileInputStream,FilterInputStream,ObjectInputStream, PipedInputStream, SequenceInputStream,StringBufferInputStream\n自己用过的例子 共享session的一个例子， request,HttpServletRequestWrapper就是HttpservletRequest的装饰类。而httpserverletReuest是接口，具体的对象还在tomcat里。 HttpServletRequestWrapper是装饰类，那这个类的作用是什么？ 为何不直接继承具体类，这样更简单。 因为具体类有多个时，我们就需要进行解耦 观察者模式 概念 在对象之间定义一对多的依赖，这样依赖，当一个对象改变状态时，它的所有依赖者都会收到通知并自动更新\n例子说明 天气展示栏，当天气有改变时，通知展示栏 首先把多个展示栏注册到天气处理中心，当天气改变时，就遍历一个一个通知。\nSubject、Observer、DisplayElement是接口\nSubject 是一个对象，代表一种类型 Observer 是观察者，update方法\nDisplayElement 是展示栏\n共享session例子 使用的就是java.util的observer。具体流程，每次请求封装session，请求结束后，判断session有没有改变，改变就更新redis的数据。\nspring监听器例子 场景说明：当用户做完一个操作后，我们需要发邮件通知。如果一个个通知就太麻烦，这时可以用事件监听。\n示例：https://blog.csdn.net/erbao_2014/article/details/68924231?locationNum=9\u0026amp;fps=1 要素：\n事件 监听 事件发布者 发生的事 适配器模式 概念 将一个类的接口，转换成客户期望的另一个接口。适配器让原本接口不兼容的类可以合作无间\n例子 比如服务提供一个接口是json格式，而需要的是String格式的。\n再比如，业务需要一个接口有用户信息和部门节点的，而提供接口并没有。就需要开发一个接口，把用户信息接口与部门节点接口聚合\n","permalink":"https://omgkill.github.io/post/codeoptimize/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/","tags":["设计模式","code style"],"title":"设计模式"},{"categories":["docs","shortcodes","index"],"contents":"Markdown is created by Daring Fireball, the original guideline is here. Its syntax, however, varies between different parsers or editors.\nPlease note that HTML fragments in markdown source will be recognized but not parsed or rendered. Also, there may be small reformatting on the original markdown source code after saving.\nParagraph and line breaks A paragraph is simply one or more consecutive lines of text. In markdown source code, paragraphs are separated by more than one blank lines. In Typora, you only need to press Return to create a new paragraph.\nPress Shift + Return to create a single line break. However, most markdown parser will ignore single line break, to make other markdown parsers recognize your line break, you can leave two whitespace at the end of the line, or insert \u0026lt;br/\u0026gt;.\nHeaders Headers use 1-6 hash characters at the start of the line, corresponding to header levels 1-6. For example:\n1# This is an H1 2 3## This is an H2 4 5###### This is an H6 In typora, input ‘#’s followed by title content, and press Return key will create a header.\nBlockquotes Markdown uses email-style \u0026gt; characters for block quoting. They are presented as:\nThis is a blockquote with two paragraphs. This is first paragraph.\nThis is second paragraph. Vestibulum enim wisi, viverra nec, fringilla in, laoreet vitae, risus.\nThis is another blockquote with one paragraph. There is three empty line to separate two blockquote.\n这是一段中文测试。\nIn typora, just input ‘\u0026gt;’ followed by quote contents a block quote is generated. Typora will insert proper ‘\u0026gt;’ or line break for you. Block quote inside anther block quote is allowed by adding additional levels of ‘\u0026gt;’.\nLists Input * list item 1 will create an un-ordered list, the * symbol can be replace with + or -.\nInput 1. list item 1 will create an ordered list, their markdown source code is like:\nRed Green Blue Red Green Blue Task List Task lists are lists with items marked as either [ ] or [x] (incomplete or complete). For example:\na task list item list syntax required normal formatting, @mentions, #1234 refs incomplete completed You can change the complete/incomplete state by click the checkbox before the item.\nSyntax Highlighting unset language:\n1function helloWorld () { 2 alert(\u0026#34;Hello, World!\u0026#34;) 3} 1plain text 2 3first line 4second line choose different style:\n1public class HelloWorld { 2 public static void main(String[] args) { 3 System.out.println(\u0026#34;Hello, World!\u0026#34;); 4 } 5} 1public class HelloWorld { 2 public static void main(String[] args) { 3 System.out.println(\u0026#34;Hello, World!\u0026#34;); 4 } 5} Math Blocks You can render LaTeX mathematical expressions using MathJax.\nInput $$, then press \u0026lsquo;Return\u0026rsquo; key will trigger an input field which accept Tex/LaTex source. Following is an example: $$ \\mathbf{V}_1 \\times \\mathbf{V}_2 = \\begin{vmatrix} \\mathbf{i} \u0026amp; \\mathbf{j} \u0026amp; \\mathbf{k} \\ \\frac{\\partial X}{\\partial u} \u0026amp; \\frac{\\partial Y}{\\partial u} \u0026amp; 0 \\ \\frac{\\partial X}{\\partial v} \u0026amp; \\frac{\\partial Y}{\\partial v} \u0026amp; 0 \\ \\end{vmatrix} $$\nIn markdown source file, math block is LaTeX expression wrapped by ‘$$’ mark:\n1$$ 2\\mathbf{V}_1 \\times \\mathbf{V}_2 = \\begin{vmatrix} 3\\mathbf{i} \u0026amp; \\mathbf{j} \u0026amp; \\mathbf{k} \\\\ 4\\frac{\\partial X}{\\partial u} \u0026amp; \\frac{\\partial Y}{\\partial u} \u0026amp; 0 \\\\ 5\\frac{\\partial X}{\\partial v} \u0026amp; \\frac{\\partial Y}{\\partial v} \u0026amp; 0 \\\\ 6\\end{vmatrix} 7$$ Tables Input | First Header | Second Header | and press return key will create a table with two column.\nAfter table is created, focus on that table will pop up a toolbar for table, where you can resize, align, or delete table. You can also use context menu to copy and add/delete column/row.\nFollowing descriptions can be skipped, as markdown source code for tables are generated by typora automatically.\nIn markdown source code, they look like:\n1| Name | Markdown | HTML tag | 2| ----------------- | ------------------- | -------------------- | 3| *Emphasis* | `*Emphasis*` | `\u0026lt;em\u0026gt;\u0026lt;/em\u0026gt;` | 4| **Strong** | `**Strong**` | `\u0026lt;strong\u0026gt;\u0026lt;/strong\u0026gt;` | 5| `code` | ``code`` | `\u0026lt;code\u0026gt;\u0026lt;/code\u0026gt;` | 6| ~~Strikethrough~~ | `~~Strikethrough~~` | `\u0026lt;del\u0026gt;\u0026lt;/del` | 7| \u0026lt;u\u0026gt;Underline\u0026lt;/u\u0026gt; | `\u0026lt;u\u0026gt;underline\u0026lt;/u\u0026gt;` | `\u0026lt;u\u0026gt;\u0026lt;/u\u0026gt;` | Name Markdown HTML tag Emphasis *Emphasis* \u0026lt;em\u0026gt;\u0026lt;/em\u0026gt; Strong **Strong** \u0026lt;strong\u0026gt;\u0026lt;/strong\u0026gt; code `code` \u0026lt;code\u0026gt;\u0026lt;/code\u0026gt; Strikethrough ~~Strikethrough~~ \u0026lt;del\u0026gt;\u0026lt;/del Underline \u0026lt;u\u0026gt;underline\u0026lt;/u\u0026gt; \u0026lt;u\u0026gt;\u0026lt;/u\u0026gt; Footnotes 1You can create footnotes like this[^footnote]. 2 3[^footnote]: Here is the *text* of the **footnote**. will produce:\nYou can create footnotes like this1.\nThis is another footnote2.\nMouse on the ‘footnote’ superscript to see content of the footnote.\nHorizontal Rules Horizontal Rules Horizontal Rules Horizontal Rules Horizontal Rules Horizontal Rules Horizontal Rules Input *** or --- on a blank line and press return will draw a horizontal line.\nLinks Markdown supports two style of links: inline and reference.\nIn both styles, the link text is delimited by [square brackets].\nTo create an inline link, use a set of regular parentheses immediately after the link text’s closing square bracket. Inside the parentheses, put the URL where you want the link to point, along with an optional title for the link, surrounded in quotes. For example:\n1This is [an example](http://example.com/ \u0026#34;Title\u0026#34;) inline link. 2 3[This link](http://example.net/) has no title attribute. will produce:\nThis is an example inline link. (\u0026lt;p\u0026gt;This is \u0026lt;a href=\u0026quot;http://example.com/\u0026quot; title:\u0026quot;Title\u0026quot;\u0026gt;)\nThis link has no title attribute. (\u0026lt;p\u0026gt;\u0026lt;a href=\u0026quot;http://example.net/\u0026quot;\u0026gt;This link\u0026lt;/a\u0026gt; has no)\nInternal Links You can set the href to headers, which will create a bookmark that allow you to jump to that section after clicking. For example:\nCommand(on Windows: Ctrl) + Click This link will jump to header Block Elements. To see how to write that, please move cursor or click that link with ⌘ key pressed to expand the element into markdown source.\nReference Links Reference-style links use a second set of square brackets, inside which you place a label of your choosing to identify the link:\n1This is [an example][id] reference-style link. 2 3Then, anywhere in the document, you define your link label like this, on a line by itself: 4 5[id]: http://example.com/ \u0026#34;Optional Title Here\u0026#34; In typora, they will be rendered like:\nThis is an example reference-style link.\nThe implicit link name shortcut allows you to omit the name of the link, in which case the link text itself is used as the name. Just use an empty set of square brackets — e.g., to link the word “Google” to the google.com web site, you could simply write:\n1[Google][] 2And then define the link: 3 4[Google]: http://google.com/ In typora click link will expand it for editing, command+click will open the hyperlink in web browser.\nURLs Typora allows you to insert urls as links, wrapped by \u0026lt;brackets\u0026gt;.\n\u0026lt;i@typora.io\u0026gt; becomes i@typora.io.\nTypora will also auto link standard URLs. e.g: www.google.com.\nImages Image looks similar with links, but it requires an additional ! char before the start of link. Image syntax looks like this:\n1![Alt text](/path/to/img.jpg) 2 3![Alt text](/path/to/img.jpg \u0026#34;Optional title\u0026#34;) You are able to use drag \u0026amp; drop to insert image from image file or we browser. And modify the markdown source code by clicking on the image. Relative path will be used if image is in same directory or sub-directory with current editing document when drag \u0026amp; drop.\nFor more tips on images, please read http://support.typora.io//Images/\nEmphasis Markdown treats asterisks (*) and underscores (_) as indicators of emphasis. Text wrapped with one * or _ will be wrapped with an HTML \u0026lt;em\u0026gt; tag. E.g:\n1*single asterisks* 2 3_single underscores_ output:\nsingle asterisks\nsingle underscores\nGFM will ignores underscores in words, which is commonly used in code and names, like this:\nwow_great_stuff\ndo_this_and_do_that_and_another_thing.\nTo produce a literal asterisk or underscore at a position where it would otherwise be used as an emphasis delimiter, you can backslash escape it:\n1\\*this text is surrounded by literal asterisks\\* Typora recommends to use * symbol.\nStrong double *’s or _’s will be wrapped with an HTML \u0026lt;strong\u0026gt; tag, e.g:\n1**double asterisks** 2 3__double underscores__ output:\ndouble asterisks\ndouble underscores\nTypora recommends to use ** symbol.\nCode To indicate a span of code, wrap it with backtick quotes (`). Unlike a pre-formatted code block, a code span indicates code within a normal paragraph. For example:\n1Use the `printf()` function. will produce:\nUse the printf() function.\nStrikethrough GFM adds syntax to create strikethrough text, which is missing from standard Markdown.\n~~Mistaken text.~~ becomes Mistaken text.\nUnderline Underline is powered by raw HTML.\n\u0026lt;u\u0026gt;Underline\u0026lt;/u\u0026gt; becomes Underline.\nEmoji :happy: Input emoji with syntax 😄.\nUser can trigger auto-complete suggestions for emoji by pressing ESC key, or trigger it automatically after enable it on preference panel. Also, input UTF8 emoji char directly from Edit -\u0026gt; Emoji \u0026amp; Symbols from menu bar is also supported.\nInline Math To use this feature, first, please enable it in Preference Panel -\u0026gt; Markdown Tab. Then use $ to wrap TeX command, for example: $\\lim_{x \\to \\infty} \\exp(-x) = 0$ will be rendered as LaTeX command.\nTo trigger inline preview for inline math: input “$”, then press ESC key, then input TeX command, a preview tooltip will be visible like below:\nHere is the text of the footnote.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nsecond footnote is here.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","permalink":"https://omgkill.github.io/post/blob/jane-theme-preview/","tags":["preview","shortcodes","tag-6"],"title":"Jane Theme Preview"},{"categories":null,"contents":"Hugo is a static site engine written in Go.\nIt makes use of a variety of open source projects including:\nCobra Viper J Walter Weatherman Cast Learn more and contribute on GitHub.\n","permalink":"https://omgkill.github.io/about/","tags":null,"title":"About"},{"categories":null,"contents":"","permalink":"https://omgkill.github.io/search/","tags":null,"title":"Search Results"}]